{"type": "paper_prowler.database.Database", "init_parameters": {"bm25_tokenization_regex": "(?u)\\b\\w\\w+\\b", "bm25_algorithm": "BM25L", "bm25_parameters": {}, "embedding_similarity_function": "dot_product"}, "documents": [{"id": "087a84528e00eddcebf167b07fecfc741cd0bd35d969d905535d2392c9515388", "content": "Test collections play a vital role in evaluation of information retrieval\n(IR) systems. Obtaining a diverse set of user queries for test collection\nconstruction can be challenging, and acquiring relevance judgments, which\nindicate the appropriateness of retrieved documents to a query, is often costly\nand resource-intensive. Generating synthetic datasets using Large Language\nModels (LLMs) has recently gained significant attention in various\napplications. In IR, while previous work exploited the capabilities of LLMs to\ngenerate synthetic queries or documents to augment training data and improve\nthe performance of ranking models, using LLMs for constructing synthetic test\ncollections is relatively unexplored. Previous studies demonstrate that LLMs\nhave the potential to generate synthetic relevance judgments for use in the\nevaluation of IR systems. In this paper, we comprehensively investigate whether\nit is possible to use LLMs to construct fully synthetic test collections by\ngenerating not only synthetic judgments but also synthetic queries. In\nparticular, we analyse whether it is possible to construct reliable synthetic\ntest collections and the potential risks of bias such test collections may\nexhibit towards LLM-based models. Our experiments indicate that using LLMs it\nis possible to construct synthetic test collections that can reliably be used\nfor retrieval evaluation.", "dataframe": null, "blob": null, "meta": {"type": "arxiv", "url": "http://arxiv.org/abs/2405.07767v1", "title": "Synthetic Test Collections for Retrieval Evaluation", "content": "http://arxiv.org/pdf/2405.07767v1", "datetime": "2024-05-13 14:11:09", "query": "synthetic data generation llms", "linkedin": "\ud83d\ude80 Exciting advancements in Information Retrieval evaluation using Large Language Models (LLMs)!\n\nTest collections are crucial for evaluating IR systems, but acquiring diverse user queries and relevance judgments can be challenging. Recent studies have shown the potential of LLMs in generating synthetic datasets for various applications, including IR.\n\nCheck out this comprehensive investigation on constructing fully synthetic test collections using LLMs. The research explores generating synthetic queries and relevance judgments, demonstrating the feasibility of using LLMs for reliable retrieval evaluation.\n\nRead the full paper here: http://arxiv.org/abs/2405.07767v1\n\n#InformationRetrieval #LLMs #AI #TechResearch #ArtificialIntelligence #NLP #TechInnovation \ud83c\udf1f", "x": "\ud83d\ude80 Exciting research alert! Can Large Language Models (LLMs) revolutionize the construction of test collections for information retrieval systems? Find out in this comprehensive study on using LLMs to generate synthetic test collections and relevance judgments: http://arxiv.org/abs/2405.07767v1 #AI #NLP #LLM #InformationRetrieval", "source_id": "3ecdbc9213aa7c131b7b434ee9fbe34f20d323c7a5d3974a6a063ee271fc40b9", "page_number": 1}, "score": null, "embedding": [-0.3488380014896393, 0.3338946998119354, 0.08413291722536087, 0.10964095592498779, 0.12859179079532623, 0.07224202156066895, -0.019731678068637848, 0.03952661529183388, 0.2615777850151062, -0.37264952063560486, -0.19557243585586548, -0.06581247597932816, 0.46897831559181213, 0.44428256154060364, 0.10500131547451019, 0.18735069036483765, -0.19112159311771393, 0.1618434637784958, -0.11537206172943115, 0.21857215464115143, 0.3530536890029907, 0.015567734837532043, 0.09974409639835358, -0.126869797706604, -0.27004891633987427, -0.006609159056097269, -0.16978369653224945, -0.04895495995879173, -0.3716340959072113, -1.3569667339324951, -0.011670051142573357, -0.22214478254318237, 0.5758540034294128, 0.17441873252391815, -0.2518382668495178, 0.02638510800898075, -0.3789442479610443, 0.09183527529239655, -0.12206552922725677, 0.2223302721977234, 0.04671204090118408, 0.06959748268127441, -0.2695983350276947, -0.04594366252422333, -0.1423555463552475, -0.16361132264137268, -0.18820583820343018, -0.04420437663793564, -0.5235346555709839, 0.03960582986474037, -0.22041688859462738, -0.22400116920471191, 0.09858454018831253, 0.04045605659484863, -0.09954577684402466, 0.10600148886442184, 0.41527771949768066, 0.1968359798192978, 0.043290186673402786, -0.024271517992019653, 0.40207505226135254, 0.11292842775583267, -0.9541235566139221, 0.056218378245830536, -0.2092723250389099, 0.19989797472953796, -0.17148452997207642, -0.0532916784286499, 0.3597913384437561, -0.02734004519879818, -0.22305770218372345, 0.0759091004729271, 0.03520842641592026, 0.4253426194190979, 0.3314041495323181, 0.259103924036026, 0.04204763472080231, -0.2515597939491272, 0.2444983273744583, -0.043511632829904556, 0.11477456986904144, -0.1180158406496048, 0.05730162560939789, -0.3351309895515442, 0.03875800594687462, -0.049020908772945404, -0.07474979013204575, -0.14868275821208954, 0.31677570939064026, 0.11726599931716919, 0.04883856698870659, -0.0406145304441452, -0.26807019114494324, 0.5306349992752075, -0.17261222004890442, -0.22771364450454712, 0.016507156193256378, 0.27687957882881165, 0.06911960244178772, 0.9098932147026062, -0.2553708851337433, 0.22770002484321594, -0.017310045659542084, -0.2122838795185089, -0.06485328078269958, -0.11619210988283157, -0.05232671648263931, -0.3804282546043396, -0.3134671747684479, -0.33740097284317017, -0.12463773787021637, -0.0023636093828827143, 0.14407600462436676, -0.17506574094295502, -0.05184505879878998, 0.224426731467247, 0.5068951845169067, 0.24543239176273346, -0.18637822568416595, -0.21255572140216827, -0.44904622435569763, 0.2495708167552948, 0.02145923301577568, -0.1375126987695694, 0.048569776117801666, -0.08436274528503418, 0.1994674950838089, 0.30844545364379883, 0.04462209716439247, -0.06752575188875198, -0.13817381858825684, -0.21279610693454742, -0.49517741799354553, -0.13792210817337036, 0.052930887788534164, -0.058615073561668396, 0.1037425845861435, -0.12497226148843765, 0.10083121806383133, 0.40914279222488403, 0.024877987802028656, 0.10437438637018204, 0.287360817193985, 0.016661176458001137, -0.5302039384841919, 0.7812649011611938, -0.23877796530723572, 0.14603294432163239, -0.30603525042533875, -0.4594229459762573, 0.19407187402248383, 0.17000414431095123, 0.036664556711912155, -0.3552372455596924, 0.2092817723751068, 0.028148606419563293, 0.10844215750694275, 0.15349392592906952, -0.3364047408103943, -0.04677748307585716, -0.06744933128356934, 0.16364510357379913, -0.16535584628582, 0.7299871444702148, -0.24239201843738556, -0.1160176619887352, -0.330045610666275, 0.19473311305046082, 0.19232487678527832, -0.06628365069627762, 0.25151193141937256, -0.08752181380987167, -0.15758346021175385, 0.05937258526682854, -0.10137379169464111, -0.08342329412698746, -0.5459420084953308, 0.2391050010919571, -0.08339150995016098, 0.03975833207368851, -0.08261856436729431, -0.37755993008613586, -0.06665612757205963, 0.24842967092990875, 0.012023534625768661, -0.20541200041770935, -0.19862554967403412, -0.06462625414133072, 0.15881887078285217, 0.22388599812984467, 0.0011397517519071698, -0.0163363479077816, -0.17299006879329681, 0.05916108563542366, 0.10844120383262634, -0.11273932456970215, 0.005688616074621677, -0.00647024717181921, 0.03112596832215786, -0.09151685982942581, 0.31102949380874634, 0.044485852122306824, 0.07547425478696823, -0.10416846722364426, -0.12628716230392456, 0.1009984090924263, 0.08673952519893646, -0.21056316792964935, 0.15786123275756836, 0.15343652665615082, -0.27474918961524963, -0.053510066121816635, 0.11667656898498535, -0.09801740199327469, -0.2809230387210846, -0.19160744547843933, 0.49832791090011597, 0.05880458280444145, -0.1851906031370163, 0.19673852622509003, -0.10876186192035675, -0.1741679608821869, -0.07102486491203308, -1.251766562461853, 0.0028528389520943165, -0.10652931034564972, 0.2350829392671585, 0.2813642919063568, -0.4340212643146515, -0.09159282594919205, 0.13763844966888428, 0.05648760125041008, 0.3323647677898407, -0.06173934414982796, 0.12768396735191345, -0.1598219871520996, 0.19222846627235413, 0.034889742732048035, -0.20652160048484802, -0.2601494789123535, 0.07950989902019501, -0.28513121604919434, 0.28005847334861755, -0.21953609585762024, 0.1377190798521042, 0.40953484177589417, -0.7189938426017761, 0.27436545491218567, -0.06765013933181763, 0.7938413023948669, -0.1820749044418335, -0.18613994121551514, -0.09555216878652573, 0.3156413435935974, 0.015473487786948681, -0.14233040809631348, -0.4701741635799408, 0.4236377775669098, 0.16063831746578217, 0.0486532524228096, 0.17975956201553345, -0.02429269254207611, -0.030484389513731003, -0.25205808877944946, -0.07079949975013733, 0.2704841196537018, -0.4515663683414459, -0.024688974022865295, -0.10143442451953888, -0.17335164546966553, -0.11156231164932251, -0.15943172574043274, 0.5787139534950256, -0.02282247133553028, 0.13022923469543457, 0.28511956334114075, -0.07216301560401917, -0.07907325029373169, -0.08812041580677032, -0.6732575297355652, -0.23568402230739594, -0.12576399743556976, -0.08591104298830032, 0.0936310738325119, -0.006973958108574152, 0.19325505197048187, -0.209942027926445, 0.3940742313861847, -0.3002215325832367, -0.04418675974011421, 0.22759082913398743, 0.13728861510753632, -0.3651493489742279, -0.11532150208950043, 0.5033685564994812, -0.15650424361228943, 0.4605247676372528, -0.10297688096761703, 0.25614991784095764, -0.18861854076385498, -0.16845718026161194, 0.06239771470427513, -0.26182815432548523, 0.4735451936721802, 0.20836222171783447, 0.2653369903564453, 0.1711520552635193, 0.1909404993057251, 0.2940540611743927, 0.45529940724372864, 0.2638966143131256, 0.2448636144399643, 0.06997570395469666, 0.022651517763733864, 0.18037839233875275, -0.3712258040904999, -0.10636425763368607, 0.2323072850704193, 0.07448543608188629, -1.1090481281280518, 0.0007898311014287174, -0.09668850898742676, 0.4707534611225128, -0.183078333735466, -0.185586616396904, 0.135294109582901, -0.1164044588804245, 0.21516430377960205, 0.2672047019004822, 0.17023789882659912, 0.11648058146238327, 0.06775509566068649, -0.1922178566455841, 0.06892786175012589, 0.15309719741344452, 0.3096602261066437, -0.19180624186992645, 0.2188423126935959, -0.5401977300643921, -0.1461281031370163, 0.1992706060409546, 1.2229803800582886, 0.024044541642069817, 0.08033086359500885, 0.04520159959793091, -0.03381628543138504, -0.06744752079248428, -0.3986457288265228, -0.11061549186706543, 0.20584815740585327, -0.08716943114995956, 0.641609787940979, -0.049002643674612045, 0.028047144412994385, 0.42916005849838257, -0.15325498580932617, 0.04093470051884651, 0.10597876459360123, -0.09516564011573792, 0.16639354825019836, -0.060598429292440414, -0.27428701519966125, 0.05994923412799835, 0.717934250831604, 0.2591702938079834, 0.03375529870390892, -0.3580535650253296, -0.13867983222007751, 0.036067474633455276, -0.2009880393743515, 0.030672166496515274, -0.13138794898986816, -0.3030749559402466, 0.47568652033805847, 0.23235957324504852, -0.010975703597068787, 0.044276054948568344, 0.023052915930747986, -0.07182201743125916, -0.0075151678174734116, 0.2215399593114853, 0.10345767438411713, -0.045392196625471115, -0.22803226113319397], "sparse_embedding": null}, {"id": "7d59e73ee346bf20e448c32497594e56f348b1d4d0fc24e02843cdbb7834702c", "content": "Test collections play a vital role in evaluation of information retrieval\n(IR) systems. Obtaining a diverse set of user queries for test collection\nconstruction can be challenging, and acquiring relevance judgments, which\nindicate the appropriateness of retrieved documents to a query, is often costly\nand resource-intensive. Generating synthetic datasets using Large Language\nModels (LLMs) has recently gained significant attention in various\napplications. In IR, while previous work exploited the capabilities of LLMs to\ngenerate synthetic queries or documents to augment training data and improve\nthe performance of ranking models, using LLMs for constructing synthetic test\ncollections is relatively unexplored. Previous studies demonstrate that LLMs\nhave the potential to generate synthetic relevance judgments for use in the\nevaluation of IR systems. In this paper, we comprehensively investigate whether\nit is possible to use LLMs to construct fully synthetic test collections by\ngenerating not only synthetic judgments but also synthetic queries. In\nparticular, we analyse whether it is possible to construct reliable synthetic\ntest collections and the potential risks of bias such test collections may\nexhibit towards LLM-based models. Our experiments indicate that using LLMs it\nis possible to construct synthetic test collections that can reliably be used\nfor retrieval evaluation.", "dataframe": null, "blob": null, "meta": {"type": "arxiv", "url": "http://arxiv.org/abs/2405.07767v1", "title": "Synthetic Test Collections for Retrieval Evaluation", "content": "http://arxiv.org/pdf/2405.07767v1", "datetime": "2024-05-13 14:11:09", "query": "synthetic data generation llms", "linkedin": "\ud83d\ude80 Exciting developments in the world of Information Retrieval (IR) systems! A recent study delves into the potential of using Large Language Models (LLMs) to construct synthetic test collections for evaluation purposes. \n\n\ud83d\udd0d Generating diverse user queries and relevance judgments for test collections can be a challenge, but leveraging LLMs offers a promising solution. By creating synthetic queries and judgments, researchers are exploring the possibility of enhancing the evaluation process without the traditional resource-intensive methods.\n\n\ud83d\udcca The study thoroughly investigates the feasibility of using LLMs to construct fully synthetic test collections and evaluates the reliability of such collections. The results suggest that synthetic test collections generated using LLMs can indeed be reliable for evaluating IR systems.\n\n\ud83d\udd17 Dive deeper into the details of this innovative research at: [Read more](http://arxiv.org/abs/2405.07767v1)\n\n#ArtificialIntelligence #NLP #LLMs #InformationRetrieval #Research #TechInnovation", "x": "\ud83d\ude80 Exciting research on using Large Language Models (LLMs) to construct synthetic test collections for Information Retrieval evaluation. Discover how LLMs can generate synthetic queries and relevance judgments efficiently! Check out the study here: http://arxiv.org/abs/2405.07767v1 #AI #NLP #LLMs #InformationRetrieval #TechResearch", "source_id": "fb6c55988e03568c9c1e1bdfed54e385db0e5737711ae9bb15730e00b716f968", "page_number": 1}, "score": null, "embedding": [-0.3488380014896393, 0.3338947594165802, 0.08413302153348923, 0.1096409410238266, 0.12859174609184265, 0.07224198430776596, -0.01973169483244419, 0.03952665254473686, 0.2615777254104614, -0.3726494610309601, -0.19557246565818787, -0.0658123642206192, 0.4689783751964569, 0.444282591342926, 0.10500134527683258, 0.18735061585903168, -0.19112159311771393, 0.16184337437152863, -0.11537201702594757, 0.21857215464115143, 0.3530536890029907, 0.015567806549370289, 0.09974405169487, -0.12686975300312042, -0.27004897594451904, -0.006609133444726467, -0.16978365182876587, -0.04895494133234024, -0.3716340959072113, -1.3569667339324951, -0.011670120060443878, -0.22214464843273163, 0.5758541226387024, 0.17441870272159576, -0.251838356256485, 0.026384949684143066, -0.3789442777633667, 0.09183529764413834, -0.12206558883190155, 0.222330242395401, 0.04671197384595871, 0.06959744542837143, -0.2695982754230499, -0.04594366252422333, -0.14235559105873108, -0.1636113077402115, -0.1882057934999466, -0.044204432517290115, -0.5235347151756287, 0.039605762809515, -0.2204168289899826, -0.22400116920471191, 0.09858459234237671, 0.04045602306723595, -0.0995456725358963, 0.10600141435861588, 0.41527771949768066, 0.19683600962162018, 0.043290261179208755, -0.024271467700600624, 0.4020750820636749, 0.11292839795351028, -0.9541236162185669, 0.05621834471821785, -0.20927223563194275, 0.19989798963069916, -0.17148450016975403, -0.0532916858792305, 0.3597913384437561, -0.02734001725912094, -0.22305770218372345, 0.0759091004729271, 0.0352083295583725, 0.4253425896167755, 0.3314042091369629, 0.2591039836406708, 0.04204750061035156, -0.2515597641468048, 0.2444983720779419, -0.04351162910461426, 0.11477458477020264, -0.11801591515541077, 0.05730168893933296, -0.335130900144577, 0.03875799477100372, -0.04902089014649391, -0.07474987953901291, -0.14868274331092834, 0.31677567958831787, 0.11726601421833038, 0.04883849620819092, -0.040614575147628784, -0.268070250749588, 0.5306349992752075, -0.1726122498512268, -0.22771373391151428, 0.01650707609951496, 0.27687954902648926, 0.0691196396946907, 0.9098931550979614, -0.2553708553314209, 0.22770008444786072, -0.017310015857219696, -0.21228384971618652, -0.06485331058502197, -0.11619209498167038, -0.05232660099864006, -0.38042834401130676, -0.31346723437309265, -0.3374009132385254, -0.12463778257369995, -0.0023636030964553356, 0.1440758854150772, -0.17506574094295502, -0.051845092326402664, 0.2244267463684082, 0.5068951845169067, 0.24543237686157227, -0.18637825548648834, -0.21255581080913544, -0.44904622435569763, 0.249570831656456, 0.02145908959209919, -0.13751260936260223, 0.048569805920124054, -0.08436280488967896, 0.1994674652814865, 0.30844539403915405, 0.04462207853794098, -0.067525714635849, -0.13817381858825684, -0.2127961814403534, -0.49517741799354553, -0.13792206346988678, 0.05293094739317894, -0.0586150586605072, 0.10374259203672409, -0.12497226893901825, 0.10083121806383133, 0.40914273262023926, 0.02487790957093239, 0.10437434911727905, 0.2873607277870178, 0.016661223024129868, -0.5302038788795471, 0.7812649607658386, -0.2387779802083969, 0.1460329294204712, -0.30603528022766113, -0.4594229757785797, 0.19407173991203308, 0.17000405490398407, 0.03666457533836365, -0.3552371859550476, 0.20928163826465607, 0.028148643672466278, 0.10844220221042633, 0.1534939855337143, -0.3364046812057495, -0.046777497977018356, -0.06744931638240814, 0.1636451929807663, -0.16535590589046478, 0.7299871444702148, -0.24239201843738556, -0.11601758748292923, -0.330045610666275, 0.194733127951622, 0.19232487678527832, -0.06628365814685822, 0.25151196122169495, -0.0875217542052269, -0.15758346021175385, 0.05937263369560242, -0.10137379169464111, -0.08342328667640686, -0.5459420084953308, 0.2391051948070526, -0.08339163661003113, 0.03975839540362358, -0.0826185941696167, -0.3775600492954254, -0.0666562169790268, 0.24842970073223114, 0.012023398652672768, -0.2054118812084198, -0.1986255794763565, -0.06462620943784714, 0.15881893038749695, 0.2238858938217163, 0.0011397537309676409, -0.016336433589458466, -0.1729901283979416, 0.05916108936071396, 0.10844114422798157, -0.11273942142724991, 0.005688630510121584, -0.006470251828432083, 0.031125973910093307, -0.09151701629161835, 0.3110295534133911, 0.04448584467172623, 0.07547428458929062, -0.10416844487190247, -0.12628719210624695, 0.10099843144416809, 0.0867394432425499, -0.21056310832500458, 0.15786145627498627, 0.15343661606311798, -0.27474913001060486, -0.05351004749536514, 0.11667660623788834, -0.09801750630140305, -0.2809230387210846, -0.19160744547843933, 0.4983278512954712, 0.058804407715797424, -0.18519049882888794, 0.1967386156320572, -0.10876180231571198, -0.17416787147521973, -0.07102493196725845, -1.251766324043274, 0.0028529127594083548, -0.10652938485145569, 0.23508292436599731, 0.28136420249938965, -0.43402138352394104, -0.09159284085035324, 0.13763858377933502, 0.05648757144808769, 0.33236488699913025, -0.06173934042453766, 0.127684086561203, -0.15982192754745483, 0.19222842156887054, 0.03488975018262863, -0.20652160048484802, -0.2601495087146759, 0.0795099213719368, -0.28513118624687195, 0.28005844354629517, -0.2195361703634262, 0.13771919906139374, 0.40953484177589417, -0.7189937829971313, 0.27436548471450806, -0.067650206387043, 0.7938412427902222, -0.1820748895406723, -0.1861400008201599, -0.0955522358417511, 0.3156414031982422, 0.015473554842174053, -0.14233043789863586, -0.470174103975296, 0.4236376881599426, 0.16063830256462097, 0.04865328595042229, 0.17975959181785583, -0.024292731657624245, -0.03048444166779518, -0.25205811858177185, -0.07079952210187912, 0.2704840898513794, -0.45156630873680115, -0.024688884615898132, -0.10143446922302246, -0.17335158586502075, -0.11156243830919266, -0.15943174064159393, 0.5787137746810913, -0.022822469472885132, 0.13022921979427338, 0.28511950373649597, -0.07216299325227737, -0.07907319813966751, -0.08812040090560913, -0.6732575297355652, -0.23568400740623474, -0.12576401233673096, -0.08591113984584808, 0.09363098442554474, -0.006973947864025831, 0.1932549923658371, -0.209942027926445, 0.3940742015838623, -0.3002214729785919, -0.0441867932677269, 0.227590873837471, 0.13728860020637512, -0.3651493489742279, -0.11532137542963028, 0.5033685564994812, -0.15650424361228943, 0.46052470803260803, -0.10297692567110062, 0.25614988803863525, -0.18861840665340424, -0.16845707595348358, 0.062397658824920654, -0.26182812452316284, 0.4735451936721802, 0.20836223661899567, 0.26533693075180054, 0.1711519956588745, 0.1909405142068863, 0.2940540611743927, 0.455299437046051, 0.26389655470848083, 0.24486373364925385, 0.06997570395469666, 0.02265148051083088, 0.18037837743759155, -0.37122565507888794, -0.10636427998542786, 0.23230724036693573, 0.07448536157608032, -1.1090481281280518, 0.0007897727191448212, -0.09668862819671631, 0.47075343132019043, -0.183078333735466, -0.185586616396904, 0.1352941393852234, -0.1164044439792633, 0.21516424417495728, 0.2672048509120941, 0.1702379435300827, 0.11648046970367432, 0.0677550733089447, -0.1922179013490677, 0.06892789155244827, 0.1530972272157669, 0.3096601963043213, -0.19180628657341003, 0.2188422679901123, -0.5401977300643921, -0.1461281180381775, 0.199270561337471, 1.2229803800582886, 0.024044545367360115, 0.08033087104558945, 0.0452016144990921, -0.033816296607255936, -0.06744752079248428, -0.3986457884311676, -0.11061543971300125, 0.2058483064174652, -0.08716937899589539, 0.6416098475456238, -0.04900269955396652, 0.0280471108853817, 0.42916005849838257, -0.15325504541397095, 0.04093474522233009, 0.10597873479127884, -0.09516562521457672, 0.16639360785484314, -0.060598500072956085, -0.27428698539733887, 0.059949297457933426, 0.717934250831604, 0.2591703534126282, 0.03375529497861862, -0.3580535352230072, -0.1386798620223999, 0.03606738895177841, -0.20098799467086792, 0.030672242864966393, -0.13138806819915771, -0.3030749261379242, 0.475686639547348, 0.23235949873924255, -0.01097577903419733, 0.0442761555314064, 0.02305295132100582, -0.07182201743125916, -0.007515151519328356, 0.2215399146080017, 0.10345771908760071, -0.045392174273729324, -0.2280322015285492], "sparse_embedding": null}, {"id": "df42bdc070f382ad8d804ff00c06958915aa09c1ba3033c1b62631ad377a15a8", "content": "Large Language models (LLMs), while powerful, exhibit harmful social biases.\nDebiasing is often challenging due to computational costs, data constraints,\nand potential degradation of multi-task language capabilities. This work\nintroduces a novel approach utilizing ChatGPT to generate synthetic training\ndata, aiming to enhance the debiasing of LLMs. We propose two strategies:\nTargeted Prompting, which provides effective debiasing for known biases but\nnecessitates prior specification of bias in question; and General Prompting,\nwhich, while slightly less effective, offers debiasing across various\ncategories. We leverage resource-efficient LLM debiasing using adapter tuning\nand compare the effectiveness of our synthetic data to existing debiasing\ndatasets. Our results reveal that: (1) ChatGPT can efficiently produce\nhigh-quality training data for debiasing other LLMs; (2) data produced via our\napproach surpasses existing datasets in debiasing performance while also\npreserving internal knowledge of a pre-trained LLM; and (3) synthetic data\nexhibits generalizability across categories, effectively mitigating various\nbiases, including intersectional ones. These findings underscore the potential\nof synthetic data in advancing the fairness of LLMs with minimal retraining\ncost.", "dataframe": null, "blob": null, "meta": {"type": "arxiv", "url": "http://arxiv.org/abs/2402.11764v1", "title": "ChatGPT Based Data Augmentation for Improved Parameter-Efficient Debiasing of LLMs", "content": "http://arxiv.org/pdf/2402.11764v1", "datetime": "2024-02-19 01:28:48", "query": "synthetic data generation llms", "linkedin": "\ud83d\ude80 Exciting advancements in the world of AI and debiasing LLMs! \ud83e\udd16 This groundbreaking work introduces a novel approach using ChatGPT to generate synthetic training data, enhancing the debiasing of Large Language Models. \n\nCheck out the full study here: http://arxiv.org/abs/2402.11764v1\n\nKey findings include:\n1\ufe0f\u20e3 Efficient production of high-quality training data for debiasing LLMs using ChatGPT.\n2\ufe0f\u20e3 Surpassing existing datasets in debiasing performance while preserving internal LLM knowledge.\n3\ufe0f\u20e3 Generalizability across categories, effectively mitigating various biases, including intersectional ones.\n\nThese results highlight the potential of synthetic data in promoting fairness in LLMs with minimal retraining costs. A must-read for all tech enthusiasts and AI professionals! \ud83c\udf10\ud83d\udca1 #AI #LLMs #Debiasing #ChatGPT #TechInnovation", "x": "\"Exciting research on using ChatGPT to enhance debiasing of Large Language Models (LLMs)! This innovative approach generates synthetic training data for efficient debiasing, surpassing existing datasets in performance. Learn more at: http://arxiv.org/abs/2402.11764v1 #AI #NLP #LLMs #Debiasing\"", "source_id": "34b57431f74c4136b0aa83972ca3e891431bc21be5ddcb028652bae40ae1aff8", "page_number": 1}, "score": null, "embedding": [-0.32588520646095276, 0.051456186920404434, 0.17917366325855255, -0.22951076924800873, 0.117042176425457, 0.14475078880786896, -0.34830811619758606, 0.06395481526851654, 0.18563805520534515, -0.21027077734470367, 0.11639576405286789, -0.3040435314178467, 0.2705221474170685, 0.2910913825035095, 0.30288541316986084, 0.12289630621671677, -0.09013062715530396, 0.11092410981655121, -0.04692119359970093, -0.02346149832010269, 0.04542367905378342, -0.2352202832698822, -0.013926483690738678, -0.07263044267892838, -0.01783851534128189, -0.0979059636592865, 0.012478243559598923, 0.04576390981674194, -0.36341941356658936, -1.368696689605713, 0.38847318291664124, 0.1386776864528656, 0.31665974855422974, -0.11464003473520279, -0.2713668942451477, -0.08210886269807816, -0.24885667860507965, 0.20234858989715576, -0.28503385186195374, 0.29566627740859985, -0.07431003451347351, 0.08717773109674454, -0.043008264154195786, -0.23199553787708282, -0.1902022361755371, -0.2423349916934967, -0.2833353579044342, 0.10521257668733597, -0.8590225577354431, -0.10191581398248672, -0.09175914525985718, -0.206577330827713, 0.17945407330989838, -0.04750678315758705, 0.09825583547353745, 0.13287247717380524, 0.16766521334648132, 0.21588070690631866, -0.0024898441042751074, 0.04818909242749214, 0.18430325388908386, 0.16828322410583496, -0.8503208160400391, 0.27962765097618103, -0.15636982023715973, 0.315446138381958, -0.07197972387075424, 0.09036200493574142, 0.10139772295951843, 0.08255224674940109, 0.0651211366057396, 0.07053831219673157, 0.38835835456848145, 0.14494937658309937, 0.297570139169693, 0.37333643436431885, 0.09044014662504196, 0.015277200378477573, 0.23833608627319336, -0.0803898423910141, -0.04617784544825554, -0.03669750690460205, -0.017210938036441803, -0.1693502813577652, -0.04569137841463089, -0.17417578399181366, 0.12867599725723267, -0.07445548474788666, 0.03797706216573715, -0.12783558666706085, -0.15560874342918396, -0.11343099176883698, 0.04201935604214668, 0.02218504250049591, -0.07609432935714722, 0.13019824028015137, -0.018224455416202545, 0.07655686885118484, -0.18733073770999908, 0.7223085165023804, -0.36116132140159607, -0.04461825266480446, -0.3337952196598053, 0.08075466752052307, 0.15521518886089325, -0.27638378739356995, -0.25792697072029114, -0.305022656917572, -0.09612582623958588, -0.033016227185726166, -0.11618635058403015, -0.07134752720594406, 0.11058133095502853, -0.2358003556728363, -0.08530714362859726, 0.16366371512413025, 0.40541815757751465, -0.12099892646074295, -0.16998596489429474, 0.2464878112077713, -0.4958495497703552, 0.34001290798187256, 0.043201252818107605, -0.10014329850673676, 0.1450165957212448, -0.12764357030391693, -0.08505313843488693, 0.6038832664489746, 0.2294897884130478, 0.02282373048365116, 0.15016239881515503, 0.05621354654431343, -0.49052053689956665, -0.0209647323936224, 0.24640455842018127, -0.05564427375793457, 0.1637762039899826, -0.05653715878725052, -0.018783770501613617, 0.1657085418701172, -0.24588564038276672, 0.07139962911605835, 0.15583844482898712, -0.039185017347335815, -0.4650760293006897, 0.4913884103298187, -0.10252974182367325, -0.06718135625123978, -0.1736762374639511, -0.2719017267227173, 0.025988630950450897, 0.20208734273910522, -0.04521575942635536, -0.33948007225990295, 0.33427974581718445, 0.3799770474433899, 0.09871029853820801, 0.281596302986145, -0.364315390586853, -0.05512901768088341, 0.01629631780087948, -0.05234672129154205, 0.03513065725564957, 0.6477655172348022, -0.16995391249656677, -0.3173379898071289, -0.3955928683280945, 0.15259429812431335, 0.23155353963375092, -0.11019016802310944, 0.18231409788131714, -0.10002958029508591, 0.08542238920927048, 0.0071565574035048485, -0.12326250970363617, 0.06384649872779846, -0.7125979661941528, 0.04697170853614807, -0.22725917398929596, 0.2478177845478058, 0.23641876876354218, -0.20152215659618378, -0.11491342633962631, 0.2465081363916397, -0.27203017473220825, -0.3202401399612427, 9.825779852690175e-05, -0.07429111003875732, 0.2089412659406662, 0.15946705639362335, -0.2262963205575943, 0.15104277431964874, 0.18394793570041656, -0.06205473095178604, -0.038176700472831726, -0.23064495623111725, -0.271366685628891, 0.11925449222326279, -0.1448030024766922, 0.00850458163768053, 0.15921244025230408, 0.15296316146850586, -0.25500693917274475, 0.15356482565402985, 0.09767599403858185, -0.10157442837953568, 0.20595204830169678, -0.12488822638988495, 0.48324933648109436, 0.2324099838733673, -0.20093435049057007, 0.026275798678398132, 0.27074408531188965, -0.13025091588497162, 0.0343756340444088, -0.08421745151281357, 0.25944578647613525, 0.4651089012622833, -0.06864844262599945, 0.14965377748012543, -0.07425045967102051, 0.005200178828090429, -0.17853988707065582, -1.261063814163208, -0.21308015286922455, 0.25569236278533936, 0.17137621343135834, -0.0209174994379282, -0.2616691589355469, 0.29086828231811523, 0.016468171030282974, 0.32817575335502625, 0.5816035270690918, 0.24921226501464844, 0.099449023604393, -0.07913340628147125, 0.09466169029474258, 0.19046801328659058, 0.06182221695780754, -0.08513641357421875, 0.17225027084350586, -0.25100672245025635, 0.2010205239057541, -0.12364061921834946, 0.23108893632888794, 0.4050254821777344, -0.4478190541267395, 0.2469176948070526, -0.08966434001922607, 0.7842197418212891, -0.32644128799438477, 0.19434809684753418, -0.03016890399158001, 0.2897610068321228, 0.30291748046875, 0.07076788693666458, -0.4925413131713867, 0.5288856625556946, 0.002056524623185396, 0.3463629186153412, -0.039753902703523636, 0.23143979907035828, -0.02279515564441681, -0.16801582276821136, 0.0040715839713811874, 0.010243145748972893, -0.7246937155723572, -0.2325892448425293, 0.05941680073738098, -0.03919592872262001, -0.26262640953063965, -0.3267791271209717, 0.1961350291967392, 0.03362526744604111, -0.12114184349775314, 0.4477417469024658, -0.013350648805499077, -0.1728479564189911, -0.020860224962234497, -0.9123855233192444, 0.052164457738399506, -0.3676987886428833, -0.13986194133758545, 0.20017562806606293, -0.1320909708738327, -0.06305575370788574, -0.2741776406764984, 0.142153799533844, -0.01292519923299551, 0.062065206468105316, -0.1049845814704895, 0.0463947057723999, 0.0026618249248713255, -0.18198612332344055, 0.6316737532615662, 0.07281547784805298, 0.17332004010677338, -0.008176534436643124, 0.25423893332481384, -0.23671236634254456, -0.2648526728153229, -0.26705268025398254, -0.21516770124435425, 0.7624513506889343, 0.2289218306541443, 0.15375131368637085, 0.23978441953659058, -0.03788452222943306, 0.0650193840265274, 0.2565004825592041, -0.15334200859069824, 0.33097317814826965, 0.169430211186409, -0.1426200270652771, 0.006278471555560827, -0.42821070551872253, -0.1717475950717926, 0.10583905875682831, -0.05688587948679924, -1.094693899154663, -0.11736875027418137, -0.2270958572626114, 0.16866111755371094, 0.049047473818063736, -0.03797833248972893, 0.06025581434369087, -0.07258311659097672, -0.12108274549245834, -0.05459333211183548, -0.12400738894939423, 0.4996959865093231, 0.28875473141670227, -0.10817933082580566, 0.12192212790250778, -0.14937031269073486, 0.3958459198474884, -0.11794828623533249, -0.020740481093525887, -0.3301783502101898, -0.0035616562236100435, -0.11372645199298859, 0.9268903136253357, 0.2042960524559021, 0.07458925247192383, 0.19828300178050995, -0.22934946417808533, 0.0853203758597374, -0.0003293656336609274, 0.07731377333402634, -0.2114633321762085, 0.25683823227882385, 0.6746576428413391, -0.10606779158115387, 0.05072480067610741, 0.4938308596611023, -0.1738308221101761, -0.11823868751525879, 0.3289543092250824, 0.0876530110836029, 0.1058540940284729, 0.19095753133296967, 0.24807460606098175, 0.03962714225053787, 0.5847651362419128, 0.10107679665088654, -0.15597569942474365, -0.34947410225868225, -0.065751813352108, 0.058750543743371964, -0.14361701905727386, 0.2033316045999527, -0.15663428604602814, -0.09334612637758255, 0.1470021903514862, -0.05129378288984299, 0.0700317993760109, -0.02478516660630703, 0.03505818545818329, -0.2259977161884308, 0.16214047372341156, -0.12357186526060104, -0.2121932953596115, -0.018310319632291794, -0.3299744129180908], "sparse_embedding": null}, {"id": "c54ef7e3de06d8aac798b4e257172f49abd7ceda66d65c78becdfeb7c1339c5d", "content": "The collection and curation of high-quality training data is crucial for\ndeveloping text classification models with superior performance, but it is\noften associated with significant costs and time investment. Researchers have\nrecently explored using large language models (LLMs) to generate synthetic\ndatasets as an alternative approach. However, the effectiveness of the\nLLM-generated synthetic data in supporting model training is inconsistent\nacross different classification tasks. To better understand factors that\nmoderate the effectiveness of the LLM-generated synthetic data, in this study,\nwe look into how the performance of models trained on these synthetic data may\nvary with the subjectivity of classification. Our results indicate that\nsubjectivity, at both the task level and instance level, is negatively\nassociated with the performance of the model trained on synthetic data. We\nconclude by discussing the implications of our work on the potential and\nlimitations of leveraging LLM for synthetic data generation.", "dataframe": null, "blob": null, "meta": {"type": "arxiv", "url": "http://arxiv.org/abs/2310.07849v2", "title": "Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations", "content": "http://arxiv.org/pdf/2310.07849v2", "datetime": "2023-10-13 01:31:59", "query": "synthetic data generation llms", "linkedin": "\ud83d\ude80 Exciting new study alert! Researchers dive into the world of Large Language Models (LLMs) for synthetic data generation in text classification models. Check out the latest findings on the impact of subjectivity on model performance when using LLM-generated synthetic data. \n\nCurious to learn more? Dive into the full study here: \nhttp://arxiv.org/abs/2310.07849v2\n\n#AI #NLP #LLMs #TextClassification #Research #Tech #ArtificialIntelligence #MachineLearning", "x": "\ud83d\ude80 New research alert! How effective are large language models in generating synthetic data for text classification models? Check out the findings on the impact of subjectivity on model performance: http://arxiv.org/abs/2310.07849v2 #AI #NLP #LLMs #DataSynthesis", "source_id": "0a0ef655e96989d0b89c12d821dc8b2b1557ea55fa385dd4246d055b467d4575", "page_number": 1}, "score": null, "embedding": [-0.06270274519920349, 0.14129891991615295, 0.13971006870269775, 0.024773020297288895, 0.2409205138683319, 0.11751479655504227, -0.44341766834259033, 0.08317718654870987, 0.14975927770137787, -0.2747926414012909, -0.06805751472711563, -0.10084991902112961, 0.15312933921813965, 0.3222736418247223, 0.12334565818309784, 0.18766215443611145, -0.027098650112748146, -0.10255811363458633, -0.19528613984584808, -0.13954007625579834, 0.3490787148475647, -0.009035090915858746, -0.027498982846736908, -0.011638441123068333, 0.04519539326429367, -0.1254495233297348, -0.16642192006111145, -0.015260660089552402, -0.4111778140068054, -1.558991551399231, 0.027973683550953865, -0.02944852039217949, 0.4124736189842224, 0.07784028351306915, -0.15026003122329712, -0.004468750208616257, -0.2566208839416504, 0.3089997172355652, -0.10015732795000076, 0.1911439746618271, -0.23413525521755219, -0.005555801093578339, -0.23352089524269104, -0.15534308552742004, 0.14520986378192902, -0.24576517939567566, -0.15772554278373718, -0.15424954891204834, -0.5845125317573547, 0.036552995443344116, -0.16836108267307281, -0.11295165866613388, 0.04163862764835358, 0.3933827877044678, 0.02209611050784588, 0.20567168295383453, 0.2557460069656372, 0.013030116446316242, 0.19616667926311493, 0.005080816335976124, 0.17307545244693756, 0.4204321801662445, -1.0848811864852905, 0.10424838960170746, -0.10688749700784683, 0.21349108219146729, -0.20156753063201904, 0.13180671632289886, 0.20496520400047302, 0.16095541417598724, -0.16840411722660065, -0.054420728236436844, 0.2725929915904999, 0.1213286742568016, 0.3674931824207306, 0.2906312644481659, 0.1385955512523651, -0.059025056660175323, 0.2702150344848633, -0.06163667514920235, 0.12258514761924744, -0.17685210704803467, -0.03566912189126015, -0.43435290455818176, -0.10059576481580734, -0.18975915014743805, 0.09130404144525528, -0.2649790644645691, 0.10698853433132172, 0.08917167782783508, -0.11869445443153381, 0.005404900759458542, -0.31156331300735474, 0.2352982461452484, -0.20408327877521515, 0.08057409524917603, 0.03523573651909828, 0.2572343349456787, -0.2613707482814789, 0.6864578723907471, -0.3970365822315216, -0.11143763363361359, -0.13562722504138947, 0.029005950316786766, 0.19067825376987457, -0.15960034728050232, -0.2593405246734619, -0.06744968891143799, -0.21444113552570343, -0.202550008893013, -0.05531404912471771, 0.09342595189809799, -0.4425014853477478, -0.09803635627031326, -0.057978857308626175, -0.18051956593990326, 0.6934233903884888, 0.03646238520741463, -0.1754896342754364, 0.04308097064495087, -0.24119611084461212, 0.10025126487016678, 0.04093211889266968, -0.18864712119102478, 0.03617647662758827, -0.08814411610364914, 0.13664531707763672, 0.5600436329841614, 0.2054157555103302, -0.10364406555891037, 0.09997303783893585, 0.12214008718729019, -0.6969346404075623, -0.07216918468475342, 0.013333569280803204, -0.24294498562812805, 0.05052966997027397, -0.09051694720983505, 0.006758122239261866, 0.2126707136631012, 0.09143522381782532, 0.20153601467609406, 0.07060746103525162, 0.06496873497962952, -0.6665464639663696, 0.7664282321929932, -0.154449462890625, 0.11751388013362885, -0.26149559020996094, -0.11618376523256302, 0.05774417519569397, 0.2452881634235382, -0.06478971242904663, -0.3447389304637909, 0.274018257856369, 0.2055083066225052, 0.17793084681034088, 0.05935071036219597, -0.4773649573326111, -0.3113879859447479, -0.017750028520822525, 0.0029865822289139032, -0.10153037309646606, 0.8530542850494385, -0.16099411249160767, -0.12886382639408112, -0.25559329986572266, 0.022102240473031998, 0.2527458965778351, -0.07995100319385529, 0.32579505443573, 0.06195077300071716, -0.12004929780960083, 0.23027953505516052, -0.11419341713190079, 0.06435124576091766, -0.6637915968894958, -0.1608750969171524, -0.15968985855579376, 0.16130845248699188, 0.21251355111598969, -0.18767140805721283, -0.27775004506111145, 0.14970043301582336, 0.08295708894729614, -0.16411791741847992, -0.1369430273771286, -0.2506859004497528, 0.19211089611053467, 0.21453550457954407, 0.08355562388896942, 0.11340274661779404, 0.07057289779186249, -0.08084657043218613, -0.06701972335577011, -0.20852522552013397, -0.09483729302883148, 0.018609285354614258, 0.06894030421972275, -0.34860390424728394, 0.0005555838579311967, 0.4815407991409302, 0.19412128627300262, -0.07382447272539139, -0.026267796754837036, 0.02480335533618927, 0.023395109921693802, 0.05755120888352394, 0.4463590383529663, 0.32079362869262695, -0.4372434914112091, -0.06471089273691177, 0.30692580342292786, -0.051021918654441833, -0.06673339009284973, 0.032973144203424454, 0.33929312229156494, 0.2763749957084656, -0.3851875066757202, 0.2492460161447525, 0.01356489397585392, 0.23306594789028168, -0.14977146685123444, -1.3114259243011475, -0.1472245305776596, 0.10630930215120316, 0.1777215301990509, 0.10265380144119263, -0.2829647660255432, -0.04397294670343399, 0.21141701936721802, 0.07169230282306671, 0.48993781208992004, 0.21005931496620178, 0.1189265325665474, -0.2923693060874939, 0.04798387363553047, -0.048500221222639084, 0.04577048495411873, 0.010723423212766647, 0.07038149237632751, -0.26777321100234985, 0.1970251053571701, -0.2573358416557312, 0.02800014428794384, 0.21648457646369934, -0.7389047145843506, 0.10002664476633072, -0.04885248467326164, 0.7000568509101868, -0.36555933952331543, 0.14971166849136353, -0.07177667319774628, 0.09157342463731766, 0.3008616268634796, -0.18164938688278198, -0.44704940915107727, 0.5580542683601379, -0.25778478384017944, 0.21896669268608093, 0.0734545886516571, 0.007310864515602589, -0.13762494921684265, -0.1753910630941391, 0.0020382509101182222, 0.1679728478193283, -0.8076971173286438, -0.20298941433429718, 0.07002092897891998, -0.09104476869106293, -0.12311484664678574, -0.579216480255127, 0.2673088014125824, 0.05670662596821785, 0.23181433975696564, 0.5310488939285278, -0.02039857767522335, -0.15544643998146057, 0.027747297659516335, -0.7601108551025391, 0.21640828251838684, -0.23190926015377045, -0.13446076214313507, 0.35909923911094666, -0.14846716821193695, 0.15931269526481628, -0.33118197321891785, 0.2056354582309723, -0.2940506637096405, -0.24237239360809326, -0.07731153070926666, 0.2207004576921463, -0.047722555696964264, -0.15622638165950775, 0.6295284628868103, -0.008708780631422997, 0.01906733773648739, 0.23553505539894104, 0.07374893128871918, -0.36211323738098145, -0.1332859843969345, -0.18783055245876312, 0.0025451229885220528, 0.45124542713165283, 0.379975825548172, 0.34646540880203247, 0.17578069865703583, 0.08974354714155197, 0.023593194782733917, 0.4204519987106323, 0.10705135762691498, 0.17138563096523285, 0.31022849678993225, 0.07138791680335999, 0.2361060231924057, -0.34942787885665894, -0.024865267798304558, 0.2261020541191101, 0.00872072484344244, -1.1068063974380493, -0.11723178625106812, -0.08120182901620865, 0.5220834612846375, -0.025381125509738922, -0.09126028418540955, 0.15349337458610535, -0.1516149938106537, 0.21919190883636475, 0.2528747022151947, 0.03316116705536842, 0.22964490950107574, 0.30448147654533386, -0.016192035749554634, 0.052628159523010254, -0.06439393013715744, 0.40737292170524597, -0.3319091498851776, 0.16918030381202698, -0.3713148832321167, 0.041701540350914, -0.002915392629802227, 1.0541191101074219, 0.03656702861189842, -0.029520146548748016, 0.21160760521888733, -0.18855388462543488, 0.06872816383838654, -0.007942460477352142, -0.09040651470422745, 0.04540999233722687, 0.18835483491420746, 0.9050746560096741, 0.1542350798845291, 0.010140911675989628, 0.5730359554290771, -0.21247784793376923, -0.010911116376519203, 0.046662356704473495, 0.05336993932723999, 0.4335554838180542, 0.17546112835407257, -0.2795095145702362, -0.18809786438941956, 0.4931975305080414, -0.0016552845481783152, 0.132182776927948, -0.3899199366569519, -0.1828104853630066, -0.005727567709982395, -0.26025664806365967, 0.11296942830085754, -0.1726807802915573, 0.10460752248764038, 0.14781902730464935, 0.2634488642215729, 0.11884079873561859, -0.12111473828554153, 0.04975264519453049, -0.14756746590137482, 0.10776016861200333, -0.1963730901479721, -0.11634528636932373, 0.11153899878263474, -0.32534563541412354], "sparse_embedding": null}, {"id": "b4600927aee0adb0b52a1af5aa725844d05c870dff2122247f964bea6e23a536", "content": "As large language models (LLMs) demonstrate unparalleled performance and\ngeneralization ability, LLMs are widely used and integrated into various\napplications. When it comes to sensitive domains, as commonly described in\nfederated learning scenarios, directly using external LLMs on private data is\nstrictly prohibited by stringent data security and privacy regulations. For\nlocal clients, the utilization of LLMs to improve the domain-specific small\nlanguage models (SLMs), characterized by limited computational resources and\ndomain-specific data, has attracted considerable research attention. By\nobserving that LLMs can empower domain-specific SLMs, existing methods\npredominantly concentrate on leveraging the public data or LLMs to generate\nmore data to transfer knowledge from LLMs to SLMs. However, due to the\ndiscrepancies between LLMs' generated data and clients' domain-specific data,\nthese methods cannot yield substantial improvements in the domain-specific\ntasks. In this paper, we introduce a Federated Domain-specific Knowledge\nTransfer (FDKT) framework, which enables domain-specific knowledge transfer\nfrom LLMs to SLMs while preserving clients' data privacy. The core insight is\nto leverage LLMs to augment data based on domain-specific few-shot\ndemonstrations, which are synthesized from private domain data using\ndifferential privacy. Such synthetic samples share similar data distribution\nwith clients' private data and allow the server LLM to generate particular\nknowledge to improve clients' SLMs. The extensive experimental results\ndemonstrate that the proposed FDKT framework consistently and greatly improves\nSLMs' task performance by around 5\\% with a privacy budget of less than 10,\ncompared to local training on private data.", "dataframe": null, "blob": null, "meta": {"type": "arxiv", "url": "http://arxiv.org/abs/2405.14212v1", "title": "Federated Domain-Specific Knowledge Transfer on Large Language Models Using Synthetic Data", "content": "http://arxiv.org/pdf/2405.14212v1", "datetime": "2024-05-23 06:14:35", "query": "synthetic data generation llms", "linkedin": "\ud83d\ude80 Exciting news in the field of AI and privacy protection! \ud83d\udee1\ufe0f Our latest research introduces the Federated Domain-specific Knowledge Transfer (FDKT) framework, enabling the transfer of domain-specific knowledge from large language models (LLMs) to small language models (SLMs) while safeguarding clients' data privacy. \n\n\ud83d\udcc8 The FDKT framework leverages LLMs to augment data based on domain-specific few-shot demonstrations synthesized from private domain data using differential privacy. This approach ensures that the synthetic samples share a similar data distribution with clients' private data, leading to significant improvements in SLMs' task performance by approximately 5% with a privacy budget of less than 10, compared to local training on private data.\n\n\ud83d\udd0d Dive deeper into the results and methodology by checking out the full research paper at: http://arxiv.org/abs/2405.14212v1\n\n#AI #PrivacyProtection #LLMs #FDKT #Research #DataPrivacy #TechInnovation", "x": "\ud83d\ude80 Exciting research in enhancing domain-specific small language models (SLMs) using Federated Domain-specific Knowledge Transfer (FDKT) framework! \ud83e\udd16\ud83d\udcda Learn how to transfer knowledge from LLMs to SLMs while preserving data privacy: http://arxiv.org/abs/2405.14212v1 #AI #NLP #LLMs #DataPrivacy #Research #FDKT \ud83d\udcca\ud83d\udd12", "source_id": "d8b1f57372d7dde3c7ebdd27d72d39a2a697cc72c963c66ec55138531066e6c3", "page_number": 1}, "score": null, "embedding": [-0.0018664882518351078, -0.28536126017570496, -0.03459811583161354, -0.39022448658943176, 0.039996881037950516, -0.03395596146583557, -0.24697910249233246, 0.008915548212826252, 0.3412875533103943, -0.3483099341392517, -0.036198023706674576, -0.035585202276706696, 0.34993329644203186, 0.37368881702423096, -0.007716996595263481, 0.27540600299835205, -0.060614340007305145, 0.14178428053855896, -0.196101576089859, 0.14143170416355133, 0.4379614591598511, -0.22246702015399933, -0.02283213660120964, -0.1030689924955368, -0.14378666877746582, 0.11701454967260361, -0.3223714828491211, -0.08251363039016724, -0.4621949791908264, -1.228664755821228, 0.06191379204392433, -0.3149498403072357, 0.03633798286318779, 0.014492516405880451, -0.03228970617055893, -0.03823177516460419, -0.33058273792266846, 0.19549334049224854, -0.18031227588653564, 0.2902936339378357, 0.1207011267542839, -0.018939055502414703, 0.07678063958883286, 0.10348554700613022, -0.021663827821612358, -0.44227465987205505, -0.151572123169899, -0.045327868312597275, -0.6268388628959656, -0.1609935760498047, -0.039731547236442566, -0.22318756580352783, -0.024956781417131424, 0.293062686920166, -0.01919306069612503, 0.24323870241641998, 0.20530082285404205, 0.114844910800457, 0.15324246883392334, 0.18319623172283173, 0.14639630913734436, 0.5754050612449646, -0.9253599047660828, 0.2997191846370697, -0.05385162681341171, 0.5582111477851868, 0.02194773592054844, -0.02624712511897087, 0.1246078684926033, 0.04185853525996208, -0.08274951577186584, 0.25589197874069214, 0.14958056807518005, 0.2758711874485016, 0.3111904561519623, 0.07408344000577927, -0.10494665801525116, 0.08061373978853226, 6.519559974549338e-05, 0.10008919984102249, 0.17323584854602814, -0.046710461378097534, 0.1558254063129425, -0.341070294380188, -0.2813379466533661, -0.008142131380736828, -0.05625360459089279, -0.3802940249443054, 0.1969297081232071, -0.08421307057142258, -0.31627002358436584, -0.07093087583780289, -0.12952670454978943, 0.08496925979852676, -0.06388124823570251, 0.06497722864151001, 0.13526834547519684, 0.12184558063745499, -0.2712373733520508, 0.5901142358779907, -0.16152429580688477, 0.22616752982139587, -0.18734164535999298, -0.08281099796295166, 0.19751018285751343, 0.10373687744140625, -0.08779538422822952, -0.08132192492485046, -0.01766217313706875, 0.07416125386953354, -0.13550080358982086, -0.019975952804088593, -0.19286103546619415, -0.12187563627958298, 0.026637403294444084, -0.08329260349273682, 0.433657169342041, 0.18755455315113068, -0.23190279304981232, -0.1089581698179245, -0.3183828890323639, 0.17969754338264465, 0.0712619423866272, -0.06242280825972557, 0.1997007131576538, -0.07848446816205978, 0.04688981547951698, 0.37436166405677795, 0.20216840505599976, 0.24755463004112244, 0.3010520339012146, -0.1831343024969101, -0.34971654415130615, -0.29911088943481445, 0.20459719002246857, -0.10300134122371674, -0.06593898683786392, -0.23976564407348633, -0.05938855558633804, 0.09369409084320068, -0.028247429057955742, -0.03039564937353134, 0.3474371135234833, -0.09208719432353973, -0.1865982711315155, 0.6941249370574951, 0.1644814908504486, 0.06874614208936691, -0.4402334988117218, 0.0573623962700367, 0.2692042589187622, 0.3419731855392456, -0.17056021094322205, -0.26807376742362976, 0.21926164627075195, -0.009745952673256397, 0.36353135108947754, 0.2585037350654602, -0.3672780990600586, -0.1603499799966812, 0.2321028709411621, -0.0066455816850066185, 0.21106761693954468, 0.8135752081871033, -0.1387784630060196, -0.504119873046875, -0.09140407294034958, 0.2535920739173889, 0.26875200867652893, -0.3861630856990814, 0.04775552824139595, 0.0358419232070446, 0.020295122638344765, -0.15400028228759766, -0.27913305163383484, 0.019445544108748436, -0.5610476136207581, -0.06975193321704865, -0.14008352160453796, 0.03782747685909271, -0.07923828065395355, -0.1679447740316391, 0.0781046599149704, 0.10776612907648087, -0.00943643320351839, -0.2856330871582031, -0.009048286825418472, -0.2589224874973297, -0.15271425247192383, 0.16019944846630096, -0.6073534488677979, 0.25818532705307007, -0.1859704852104187, -0.06440958380699158, -0.05282454565167427, -0.07639405131340027, -0.19144895672798157, 0.1256810426712036, 0.04189349338412285, -0.15607839822769165, 0.1702508181333542, 0.43651849031448364, -0.050146155059337616, 0.0030639697797596455, -0.06852306425571442, -0.08631126582622528, 0.09061672538518906, -0.07052945345640182, 0.008337709121406078, 0.22624611854553223, -0.2909858524799347, 0.16017583012580872, 0.06544452160596848, -0.08224746584892273, -0.1512220948934555, 0.0931476354598999, 0.2558528184890747, 0.23493321239948273, -0.08136893063783646, -0.11061280220746994, 0.16442252695560455, 0.3064942955970764, -0.2697668671607971, -1.081972360610962, -0.1622379869222641, -0.001165009685792029, 0.07061809301376343, 0.3798975348472595, -0.2837832272052765, 0.13291357457637787, 0.18338046967983246, 0.12114433199167252, 0.33206936717033386, 0.45937079191207886, -0.14575223624706268, -0.43504586815834045, 0.2519753873348236, -0.01987687312066555, -0.12025386840105057, 0.05041075870394707, 0.18905553221702576, -0.10690484195947647, 0.24657483398914337, -0.20637980103492737, 0.0640764981508255, 0.3054620325565338, -0.582862377166748, 0.15220873057842255, -0.1110413447022438, 0.777820885181427, -0.27181321382522583, 0.06413227319717407, -0.3847557306289673, 0.1366218477487564, 0.2241085022687912, 0.1346813589334488, -0.6637555956840515, 0.19877523183822632, -0.20870846509933472, 0.13897062838077545, 0.1448378562927246, 0.2022646814584732, -0.06444039195775986, -0.01814867928624153, -0.0800171047449112, 0.11319346725940704, -0.6580791473388672, -0.2843056619167328, -0.017341021448373795, -0.161077082157135, -0.18204215168952942, -0.1974419504404068, 0.41611814498901367, 0.0008652808028273284, 0.0004314785765018314, 0.431703120470047, 0.022824835032224655, -0.09337665885686874, -0.09430709481239319, -0.31699565052986145, -0.040385354310274124, -0.046786025166511536, 0.1944768875837326, 0.06855501979589462, -0.17938131093978882, 0.06755605340003967, -0.35940080881118774, 0.23009246587753296, -0.5200045108795166, -0.13341552019119263, 0.011629948392510414, 0.34154894948005676, -0.12603461742401123, -0.11578470468521118, 0.5252876281738281, 0.2854141592979431, 0.2990737855434418, -0.05542850121855736, 0.2619436979293823, -0.18392308056354523, 0.09554101526737213, -0.5701740384101868, 0.03828045353293419, 0.7851638197898865, 0.12759895622730255, 0.12613926827907562, 0.16988828778266907, 0.16533394157886505, 0.015648256987333298, 0.36821576952934265, 0.341086208820343, -0.007284143008291721, -0.028501441702246666, -0.1544509381055832, -0.1855214685201645, -0.27995654940605164, -0.10591987520456314, 0.31320393085479736, -0.12420165538787842, -1.187362551689148, -0.15998056530952454, -0.24923844635486603, 0.3358149230480194, -0.09949982166290283, 0.10111886262893677, 0.33313459157943726, -0.062284089624881744, 0.0318102203309536, 0.21185985207557678, -0.017580842599272728, 0.18982431292533875, 0.20914682745933533, -0.016342034563422203, 0.18711133301258087, -0.0972285196185112, 0.2706458866596222, -0.040741149336099625, -0.12210414558649063, -0.33142784237861633, -0.14289197325706482, 0.304036408662796, 1.063277244567871, 0.013670734129846096, -0.1105443462729454, 0.09344141185283661, -0.001898284419439733, 0.29410016536712646, 0.03462962433695793, 0.070943184196949, -0.06501179933547974, 0.14653079211711884, 0.3886248469352722, 0.014470587484538555, 0.007521524094045162, 0.46660947799682617, -0.07186967134475708, -0.14854401350021362, 0.10957928001880646, 0.10879562795162201, 0.3840491473674774, -0.37589457631111145, 0.015595493838191032, 0.33202502131462097, 0.5523245334625244, 0.1039910688996315, -0.0010345788905397058, -0.3257797658443451, -0.08004741370677948, 0.011420954018831253, -0.11562198400497437, -0.3104763925075531, 0.055321916937828064, -0.13842365145683289, 0.2566399574279785, -0.08961454778909683, 0.16727067530155182, 0.06798906624317169, -0.09915726631879807, -0.14215803146362305, 0.12013955414295197, -0.20487233996391296, -0.27604371309280396, 0.0023189750500023365, -0.2501605749130249], "sparse_embedding": null}, {"id": "3713969ed3f7ab6fd67b23404f5d0a1a80063500a2bf6c926288545d06721030", "content": "Text data has become extremely valuable due to the emergence of machine\nlearning algorithms that learn from it. A lot of high-quality text data\ngenerated in the real world is private and therefore cannot be shared or used\nfreely due to privacy concerns. Generating synthetic replicas of private text\ndata with a formal privacy guarantee, i.e., differential privacy (DP), offers a\npromising and scalable solution. However, existing methods necessitate DP\nfinetuning of large language models (LLMs) on private data to generate DP\nsynthetic data. This approach is not viable for proprietary LLMs (e.g.,\nGPT-3.5) and also demands considerable computational resources for open-source\nLLMs. Lin et al. (2024) recently introduced the Private Evolution (PE)\nalgorithm to generate DP synthetic images with only API access to diffusion\nmodels. In this work, we propose an augmented PE algorithm, named Aug-PE, that\napplies to the complex setting of text. We use API access to an LLM and\ngenerate DP synthetic text without any model training. We conduct comprehensive\nexperiments on three benchmark datasets. Our results demonstrate that Aug-PE\nproduces DP synthetic text that yields competitive utility with the SOTA DP\nfinetuning baselines. This underscores the feasibility of relying solely on API\naccess of LLMs to produce high-quality DP synthetic texts, thereby facilitating\nmore accessible routes to privacy-preserving LLM applications. Our code and\ndata are available at https://github.com/AI-secure/aug-pe.", "dataframe": null, "blob": null, "meta": {"type": "arxiv", "url": "http://arxiv.org/abs/2403.01749v1", "title": "Differentially Private Synthetic Data via Foundation Model APIs 2: Text", "content": "http://arxiv.org/pdf/2403.01749v1", "datetime": "2024-03-04 05:57:50", "query": "synthetic data generation llms", "linkedin": "\ud83c\udf1f Exciting News in the World of AI and Privacy-Preserving Technologies! \ud83c\udf1f\n\nText data privacy is a crucial concern in the age of machine learning. Check out the groundbreaking work by Lin et al. introducing the Aug-PE algorithm, designed to generate differentially private (DP) synthetic text data using API access to large language models (LLMs) without the need for model training.\n\nCurious to learn more about how Aug-PE can revolutionize privacy-preserving LLM applications? Dive into the details and explore the impressive results from comprehensive experiments on benchmark datasets. The study showcases that Aug-PE produces high-quality DP synthetic text comparable to state-of-the-art DP finetuning baselines.\n\nReady to explore the future of privacy-preserving AI applications? Access the code and data at: [https://github.com/AI-secure/aug-pe](http://arxiv.org/abs/2403.01749v1)\n\n#AI #PrivacyPreservation #MachineLearning #DifferentialPrivacy #AugmentedPE #TechInnovation", "x": "\ud83d\ude80 Exciting new research alert! Aug-PE algorithm enables generating high-quality differentially private synthetic text without model training. Check out the groundbreaking study by Lin et al. (2024) and explore the code and data at: \n\n\ud83d\udd17 http://arxiv.org/abs/2403.01749v1\n\n#AI #NLP #LLMs #PrivacyPreservation #MachineLearning", "source_id": "524aed14c0346e98f527a3dd7732e5a88b79652c0e80b51768334da3f0850d98", "page_number": 1}, "score": null, "embedding": [-0.4291870594024658, -0.10987675935029984, -0.10655142366886139, -0.2902047634124756, 0.06917479634284973, 0.10741641372442245, -0.3048669397830963, 0.13748416304588318, 0.3194192945957184, -0.20526398718357086, 0.11524054408073425, -0.21398039162158966, 0.26470956206321716, -0.03159294277429581, 0.10704893618822098, 0.29436033964157104, -0.07339855283498764, -0.1275624930858612, -0.2935941219329834, 0.023414863273501396, 0.467397540807724, -0.07375524193048477, 0.02591385506093502, -0.4178381562232971, -0.13314229249954224, 0.02522156946361065, -0.10566651821136475, 0.05321599915623665, -0.2521522641181946, -1.3572381734848022, 0.24597328901290894, -0.24317197501659393, 0.24765080213546753, -0.09379339218139648, -0.16382862627506256, 0.030122822150588036, -0.37700414657592773, 0.40784740447998047, -0.2829825282096863, 0.16309323906898499, -0.20305736362934113, -0.11165878921747208, -0.18599894642829895, 0.004911675583571196, 0.1675688922405243, -0.23902961611747742, -0.3163624405860901, -0.08138668537139893, -0.47089409828186035, -0.049021657556295395, 0.00911865383386612, 0.19452030956745148, -0.04176080599427223, 0.2863551378250122, 0.0995720699429512, 0.04512610286474228, 0.3116237223148346, 0.009745021350681782, 0.024864155799150467, 0.1554258018732071, 0.045125335454940796, 0.4537762999534607, -0.9542045593261719, 0.30536195635795593, -0.10309531539678574, 0.37561771273612976, -0.3148249089717865, 0.01182633824646473, 0.3182671070098877, -0.17746366560459137, -0.034210409969091415, 0.3457828462123871, 0.19274236261844635, 0.11701195687055588, 0.2967613935470581, 0.4526892900466919, 0.14556987583637238, -0.1896955519914627, 0.18537898361682892, -0.0026341222692281008, 0.10411114990711212, 0.06697925180196762, 0.03545455262064934, -0.14898960292339325, -0.12389160692691803, -0.044797539710998535, 0.13563811779022217, -0.30560970306396484, 0.2439599484205246, -0.20049236714839935, -0.21346507966518402, 0.003440586384385824, -0.023229064419865608, 0.1083725094795227, -0.17393572628498077, 0.14789240062236786, -0.1009591668844223, 0.014839082024991512, -0.1387665569782257, 0.5459895133972168, -0.3220401108264923, 0.08064356446266174, -0.10834489017724991, 0.06329837441444397, 0.17732690274715424, -0.16440263390541077, -0.2024739533662796, -0.13588008284568787, -0.30839791893959045, 0.04414628818631172, 0.09034716337919235, -0.0042667207308113575, -0.02077212929725647, 0.07876367121934891, -0.23202067613601685, -0.10184548795223236, 0.4014061391353607, -0.026573877781629562, -0.11782129853963852, -0.10641442239284515, -0.17336821556091309, 0.2785351872444153, -0.10698242485523224, 0.1374308466911316, 0.15030640363693237, -0.14662933349609375, 0.04933831840753555, 0.5299703478813171, 0.09269892424345016, 0.03547108918428421, 0.13977181911468506, 0.09054730087518692, -0.4407247006893158, -0.26264262199401855, 0.008573111146688461, -0.22195734083652496, -0.179942324757576, -0.21157827973365784, 0.1451796442270279, -0.07002151012420654, -0.16032463312149048, 0.1953897476196289, 0.18572649359703064, -0.009748974815011024, -0.3286805748939514, 0.6647255420684814, 0.24512174725532532, 0.20701999962329865, -0.3691357970237732, -0.3292267918586731, 0.1739971935749054, 0.10997285693883896, -0.1480848491191864, -0.15620344877243042, 0.41794437170028687, -0.129311665892601, 0.16523617506027222, 0.30370956659317017, -0.32480406761169434, 0.11734195798635483, 0.06160939857363701, 0.11047782003879547, -0.029638485983014107, 1.1148216724395752, -0.15124404430389404, -0.491580992937088, 0.02030581422150135, 0.09326091408729553, 0.24673138558864594, -0.1521129310131073, 0.2810158431529999, -0.014492124319076538, -0.0927080363035202, 0.2647082209587097, -0.14085876941680908, 0.04503662511706352, -0.6340011954307556, -0.11973420530557632, -0.20081526041030884, 0.23059935867786407, -0.2658504247665405, -0.2809734344482422, -0.2305474579334259, 0.14386354386806488, -0.004263830371201038, -0.26218387484550476, -0.08067622780799866, -0.21307089924812317, 0.0563577301800251, 0.3091602027416229, -0.04165572300553322, 0.3113554120063782, -0.2025000900030136, -0.0062160673551261425, -0.11918268352746964, -0.3166021406650543, -0.05704604089260101, 0.08463772386312485, 0.12192314118146896, -0.16213534772396088, -0.05256020277738571, 0.25733765959739685, 0.05651348829269409, -0.17579641938209534, -0.2555276155471802, -0.060671109706163406, 0.033597178757190704, 0.050303276628255844, 0.19239823520183563, 0.3228408396244049, -0.2648454010486603, -0.0837264284491539, 0.17422328889369965, -0.13085836172103882, -0.3300672173500061, 0.23089885711669922, 0.11121384799480438, 0.10290537774562836, -0.18665246665477753, 0.1876850426197052, -0.13844554126262665, 0.14772078394889832, -0.15804730355739594, -1.0019162893295288, -0.24304518103599548, -0.0430770106613636, -0.006932568736374378, 0.2990112900733948, -0.3786335289478302, 0.04134431481361389, -0.17035983502864838, 0.2794581353664398, 0.5465908050537109, 0.511677086353302, -0.01880510151386261, -0.21504449844360352, 0.2691400945186615, -0.06348750740289688, 0.10081207007169724, 0.08856707811355591, 0.32525166869163513, 0.008833813481032848, 0.05369657278060913, -0.3056578040122986, 0.04298987612128258, 0.20433880388736725, -0.6390594244003296, 0.2881365716457367, -0.11434875428676605, 0.8873940706253052, -0.07332039624452591, 0.18176116049289703, -0.027786798775196075, 0.09421129524707794, 0.2616358995437622, -0.05374443158507347, -0.7932963967323303, 0.1744554489850998, -0.12674029171466827, -0.14205028116703033, 0.13017183542251587, 0.15669944882392883, -0.24577219784259796, -0.008466826751828194, 0.1583413928747177, -0.08300764858722687, -0.7071980834007263, -0.14798232913017273, -0.25206419825553894, -0.14316387474536896, -0.1506551206111908, -0.27692902088165283, 0.4335053861141205, 0.4295061230659485, 0.18403953313827515, 0.5424576997756958, -0.10213746875524521, -0.13983695209026337, -0.33935508131980896, -0.4263472259044647, -0.06249784678220749, -0.2568284869194031, -0.0356982946395874, 0.10668236017227173, -0.04564942792057991, -0.02633473090827465, -0.3580663800239563, 0.084502212703228, -0.24960504472255707, -0.09052518010139465, -0.22946877777576447, 0.22510388493537903, -0.023604650050401688, -0.010549165308475494, 0.6323372721672058, 0.028115004301071167, 0.12440488487482071, 0.09227535128593445, 0.17903591692447662, -0.10355297476053238, 0.06712745130062103, -0.2281772345304489, -0.2730778455734253, 0.5558294057846069, 0.40309250354766846, 0.3375866115093231, 0.284316748380661, -0.017635103315114975, 0.35562512278556824, 0.35547178983688354, 0.19088782370090485, 0.05744222179055214, 0.11325077712535858, 0.09826018661260605, 0.1378936916589737, -0.39805611968040466, -0.1277625560760498, 0.3859047591686249, 0.08279023319482803, -1.173597812652588, -0.06245243176817894, -0.23295186460018158, 0.2977347671985626, -0.21436727046966553, 0.15064644813537598, 0.3592328727245331, 0.025720743462443352, -0.04417584463953972, 0.10748082399368286, -0.22466999292373657, 0.21504609286785126, 0.16626189649105072, -0.18065838515758514, 0.29660651087760925, -0.11958146840333939, 0.2998022139072418, -0.05589418485760689, -0.058314140886068344, -0.3450494408607483, 0.09343080222606659, -0.1260197013616562, 1.0226726531982422, -0.27794837951660156, -0.17982834577560425, 0.11474978178739548, -0.00018451843061484396, 0.27729955315589905, -0.20018908381462097, -0.06905008107423782, -0.24543032050132751, 0.1257123351097107, 0.47458240389823914, -0.0738857164978981, 0.18780289590358734, 0.4559614360332489, -0.1848403662443161, -0.05029934644699097, -0.05107022076845169, 0.08456479758024216, 0.24269047379493713, 0.050148479640483856, -0.08686771243810654, 0.0734742134809494, 0.23227143287658691, 0.29064884781837463, -0.01302128192037344, -0.14134006202220917, -0.0383564792573452, 0.08114472776651382, -0.24440282583236694, 0.25465887784957886, -0.2311541736125946, 0.003496558405458927, 0.33859071135520935, 0.37230122089385986, -0.06511722505092621, 0.09196515381336212, 0.029610037803649902, -0.07656556367874146, 0.1386222094297409, -0.13142940402030945, -0.11735451221466064, 0.4006313979625702, -0.19547995924949646], "sparse_embedding": null}, {"id": "b2eae6e6f459f03d6b118f4b9988653e23007b6380e0c3cdd7c9985cf08a437e", "content": "Large language models (LLMs) suffer from catastrophic forgetting during\ncontinual learning. Conventional rehearsal-based methods rely on previous\ntraining data to retain the model's ability, which may not be feasible in\nreal-world applications. When conducting continual learning based on a\npublicly-released LLM checkpoint, the availability of the original training\ndata may be non-existent. To address this challenge, we propose a framework\ncalled Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic\ninstances for rehearsal. Concretely, we first employ the base LLM for\nin-context learning to generate synthetic instances. Subsequently, we utilize\nthe latest LLM to refine the instance outputs based on the synthetic inputs,\npreserving its acquired ability. Finally, we select diverse high-quality\nsynthetic instances for rehearsal in future stages. Experimental results\ndemonstrate that SSR achieves superior or comparable performance compared to\nconventional rehearsal-based approaches while being more data-efficient.\nBesides, SSR effectively preserves the generalization capabilities of LLMs in\ngeneral domains.", "dataframe": null, "blob": null, "meta": {"type": "arxiv", "url": "http://arxiv.org/abs/2403.01244v2", "title": "Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal", "content": "http://arxiv.org/pdf/2403.01244v2", "datetime": "2024-05-25 12:17:29", "query": "synthetic data generation llms", "linkedin": "\ud83d\ude80 Exciting News in AI Research \ud83d\ude80\n\nLarge language models (LLMs) face a significant challenge in continual learning due to catastrophic forgetting. Conventional methods rely on previous training data for rehearsal, which may not be practical in real-world scenarios. Our latest research introduces a cutting-edge framework, Self-Synthesized Rehearsal (SSR), to tackle this issue.\n\n\ud83d\udd0d SSR leverages LLMs to generate synthetic instances for rehearsal, enabling continual learning without access to original training data. By utilizing the base LLM for in-context learning to create synthetic instances and refining them with the latest LLM, SSR maintains and enhances the model's acquired abilities. Moreover, diverse high-quality synthetic instances are selected for future rehearsal, ensuring data-efficient performance.\n\n\ud83d\udcca Experimental results showcase that SSR outperforms traditional rehearsal-based methods while preserving the generalization capabilities of LLMs in various domains.\n\nLearn more about our innovative SSR framework in our research paper: http://arxiv.org/abs/2403.01244v2\n\n#AI #LLM #ContinualLearning #Research #TechInnovation #NLP #SSR #ArtificialIntelligence #DataEfficiency", "x": "\ud83d\ude80 Exciting research alert! Addressing catastrophic forgetting in Large Language Models (LLMs) during continual learning, a new framework called Self-Synthesized Rehearsal (SSR) has been proposed. SSR generates synthetic instances for rehearsal, achieving superior performance while being more data-efficient. Check out the results here: http://arxiv.org/abs/2403.01244v2 #AI #NLP #LLM #Research #TechInnovation \ud83e\udd16\ud83d\udcda", "source_id": "7e656a036e346c7815e8fe235c8843c66073ddc34f0adf4f2a7ba7187b49d910", "page_number": 1}, "score": null, "embedding": [-0.3815949857234955, 0.06480429321527481, 0.19226329028606415, -0.19486968219280243, -0.1329120397567749, 0.2341940999031067, -0.300415962934494, -0.11995147168636322, 0.47389456629753113, -0.4108138084411621, 0.023740801960229874, -0.08459772169589996, 0.49150630831718445, 0.39763614535331726, 0.17734669148921967, 0.1548987179994583, -0.2075279802083969, 0.24429327249526978, 0.19359040260314941, -0.17367056012153625, 0.22768446803092957, -0.23611557483673096, -0.10102922469377518, 0.0876164510846138, 0.08585672080516815, -0.14963848888874054, -0.12291835993528366, -0.09154842048883438, -0.14427873492240906, -1.5243940353393555, 0.1439262479543686, -0.00945792905986309, 0.02101890742778778, 0.09695371240377426, -0.4352850914001465, -0.10674527287483215, -0.33754295110702515, 0.22151640057563782, -0.06996330618858337, 0.320064514875412, -0.1487892121076584, 0.28739333152770996, -0.20005619525909424, -0.14138883352279663, 0.0655912533402443, -0.34857189655303955, 0.06540517508983612, -0.062484871596097946, -0.4131771922111511, 0.039938535541296005, -0.09096451103687286, -0.1401703804731369, 0.32762956619262695, 0.16088616847991943, -0.041162822395563126, -0.07531983405351639, 0.27346256375312805, 0.508137583732605, 0.13399171829223633, -0.10701637715101242, 0.24123068153858185, 0.1818958967924118, -1.0153578519821167, -0.028511352837085724, -0.15274623036384583, 0.19014225900173187, 0.09700212627649307, -0.035608287900686264, 0.2627652883529663, 0.34113427996635437, -0.28046929836273193, 0.1639130413532257, 0.09119667857885361, 0.23368367552757263, 0.390934556722641, 0.06547007709741592, 0.1536460518836975, -0.027722228318452835, 0.271510511636734, 0.067971371114254, 0.029480233788490295, -0.09351667016744614, -0.03511686250567436, -0.2900681793689728, -0.306826651096344, 0.03291292116045952, 0.045743782073259354, -0.08976680040359497, 0.3472965359687805, 0.004233037121593952, -0.24111708998680115, -0.17586082220077515, -0.08951551467180252, 0.10079789906740189, -0.17688381671905518, 0.04064788669347763, 0.08218761533498764, 0.24861085414886475, -0.2315533608198166, 0.6913825869560242, -0.12264090776443481, -0.04035515710711479, 0.026806537061929703, 0.26600098609924316, 0.0565749891102314, -0.1753973364830017, -0.09875059872865677, -0.19543348252773285, -0.34337949752807617, 0.0001751295494614169, -0.043501585721969604, 0.03374633193016052, -0.12496698647737503, -0.12396170198917389, -0.19031009078025818, 0.07472354173660278, 0.5566895604133606, 0.15415926277637482, -0.09711437672376633, 0.06125941127538681, -0.1969841569662094, 0.12737131118774414, 0.0341527983546257, -0.3091490566730499, 0.07946854084730148, -0.19740581512451172, -0.31737035512924194, 0.5468471646308899, 0.30615848302841187, -0.17331373691558838, 0.17046408355236053, -0.16188128292560577, -0.4792076647281647, -0.2583213150501251, 0.03489493951201439, -0.3652550280094147, 0.03836121782660484, -0.20715701580047607, 0.21066975593566895, -0.26938167214393616, -0.0300836730748415, 0.18060874938964844, 0.37979012727737427, -0.12495606392621994, -0.4780987501144409, 0.7855582237243652, -0.005918177310377359, 0.20133517682552338, -0.2752525806427002, -0.06878572702407837, -0.17667530477046967, 0.06894530355930328, -0.15362440049648285, -0.449443519115448, 0.27874717116355896, 0.313068687915802, -0.03866118565201759, 0.34341299533843994, -0.1381978690624237, -0.019244801253080368, -0.19698505103588104, 0.0806795135140419, 0.15724073350429535, 0.6865642666816711, -0.1336449831724167, -0.3644867241382599, -0.34122323989868164, 0.20482033491134644, 0.3225537836551666, -0.003311082487925887, 0.08256680518388748, 0.15858447551727295, -0.09862834215164185, -0.24516849219799042, -0.1319543868303299, 0.19700437784194946, -0.506624698638916, -0.08033329993486404, 0.05316763371229172, 0.2715863287448883, -0.00831281766295433, -0.45575788617134094, -0.16596341133117676, 0.16241823136806488, 0.03593279421329498, -0.22044290602207184, 0.008257448673248291, -0.40797513723373413, 0.1915058046579361, 0.30494722723960876, -0.05316852405667305, 0.33204180002212524, 0.1417284458875656, 0.07425494492053986, -0.1890280544757843, -0.2339821606874466, -0.09361395239830017, -0.26228058338165283, 0.08047778159379959, -0.2114747315645218, -0.151285782456398, 0.21284961700439453, -0.10019262880086899, -0.037516772747039795, 0.5070717930793762, -0.07609246671199799, 0.11105524003505707, -0.021576933562755585, 0.40782904624938965, 0.46326079964637756, -0.4692530930042267, -0.031556643545627594, 0.3518272936344147, 0.17941616475582123, -0.16354985535144806, 0.06488178670406342, -0.08416160941123962, 0.2181725949048996, -0.14142845571041107, 0.1431400328874588, 0.2656033933162689, 0.30377933382987976, -0.3148035407066345, -1.189820647239685, -0.26587891578674316, 0.13522718846797943, 0.11034277081489563, 0.24921363592147827, -0.21323524415493011, 0.07379855215549469, 0.3569934666156769, 0.24745362997055054, 0.10661152005195618, 0.19020481407642365, 0.10960575193166733, -0.3891333043575287, 0.17518694698810577, -0.23019260168075562, -0.185659259557724, -0.0910206213593483, 0.05054658651351929, -0.1772468239068985, 0.23839685320854187, -0.05673041194677353, 0.30481311678886414, -0.001411384204402566, -0.7177629470825195, 0.2211897075176239, -0.12979069352149963, 0.7815149426460266, -0.3351130783557892, 0.44512268900871277, -0.03427871689200401, 0.05373283475637436, 0.32484540343284607, -0.06567975878715515, -0.5723230838775635, 0.031065288931131363, -0.08511289209127426, 0.1277192384004593, 0.2182278037071228, 0.2387673556804657, -0.12589794397354126, -0.08538012206554413, 0.005004719831049442, -0.05623563006520271, -0.6879569888114929, -0.3112315833568573, 0.0701124295592308, -0.1799256056547165, -0.002685467479750514, -0.31907257437705994, 0.2120063304901123, 0.14446358382701874, -0.16052353382110596, 0.31047794222831726, -0.04346247389912605, -0.19732795655727386, 0.039905846118927, -0.5399602651596069, -0.01085247378796339, -0.2836478352546692, -0.09062456339597702, 0.33152347803115845, 0.11335544288158417, -0.04822571948170662, -0.15194369852542877, 0.2877901494503021, -0.19033488631248474, 0.17662979662418365, -0.005756495054811239, 0.3739493191242218, -0.20545907318592072, -0.2630162239074707, 0.6633395552635193, 0.06610127538442612, -0.02944989502429962, -0.017443252727389336, 0.03427690640091896, -0.2782320976257324, -0.4957210421562195, -0.478443443775177, 0.09344061464071274, 0.32676950097084045, 0.08853519707918167, 0.12433360517024994, 0.06403296440839767, 0.07743700593709946, 0.4215780794620514, 0.4462019205093384, 0.31928783655166626, 0.2995237410068512, 0.20257875323295593, -0.041226089000701904, 0.08695374429225922, -0.2819094657897949, -0.009819935075938702, 0.21391455829143524, -0.15381920337677002, -1.2332829236984253, -0.0823952928185463, -0.3008321523666382, 0.5679198503494263, -0.22350525856018066, 0.03909822180867195, -0.0714196190237999, 0.05941230058670044, -0.2319229692220688, 0.41263094544410706, -0.16413334012031555, 0.09723145514726639, 0.22221292555332184, 0.20576012134552002, 0.16814863681793213, 0.01008895318955183, 0.5818696022033691, -0.16324689984321594, 0.23443400859832764, -0.7251099944114685, 0.1876894235610962, 0.08992055803537369, 0.9023405909538269, 0.09364891052246094, 0.12367826700210571, 0.22346776723861694, -0.04174236208200455, 0.06123462691903114, 0.04610196873545647, -0.0604214109480381, -0.15033093094825745, -0.029469387605786324, 0.6219382286071777, -0.03382406011223793, 0.18635229766368866, 0.05671006441116333, -0.2922412157058716, 0.1133187785744667, 0.14279380440711975, 0.054897673428058624, -0.040461424738168716, -0.0005501809646375477, -0.021324628964066505, -0.00017902693070936948, 0.8350028395652771, 0.08942637592554092, 0.24378006160259247, -0.4989364445209503, -0.1790555864572525, -0.08070351928472519, -0.26075732707977295, -0.06886997073888779, 0.035309530794620514, -0.10438535362482071, 0.026014454662799835, 0.10481622815132141, 0.14783349633216858, -0.05077042803168297, 0.041025999933481216, -0.07020047307014465, 0.1952841728925705, -0.1718677431344986, 0.26268866658210754, -0.027470173314213753, -0.1648205816745758], "sparse_embedding": null}, {"id": "4f8f5a6c2959929148959dfca527bf9ef1f928bcb3dc7cd0e483a70dbbc71ea6", "content": "Natural Language Processing (NLP) models optimized for predictive performance\noften make high confidence errors and suffer from vulnerability to adversarial\nand out-of-distribution data. Existing work has mainly focused on mitigation of\nsuch errors using either humans or an automated approach. In this study, we\nexplore the usage of large language models (LLMs) for data augmentation as a\npotential solution to the issue of NLP models making wrong predictions with\nhigh confidence during classification tasks. We compare the effectiveness of\nsynthetic data generated by LLMs with that of human data obtained via the same\nprocedure. For mitigation, humans or LLMs provide natural language\ncharacterizations of high confidence misclassifications to generate synthetic\ndata, which are then used to extend the training set. We conduct an extensive\nevaluation of our approach on three classification tasks and demonstrate its\neffectiveness in reducing the number of high confidence misclassifications\npresent in the model, all while maintaining the same level of accuracy.\nMoreover, we find that the cost gap between humans and LLMs surpasses an order\nof magnitude, as LLMs attain human-like performance while being more scalable.", "dataframe": null, "blob": null, "meta": {"type": "arxiv", "url": "http://arxiv.org/abs/2403.17860v2", "title": "Exploring LLMs as a Source of Targeted Synthetic Textual Data to Minimize High Confidence Misclassifications", "content": "http://arxiv.org/pdf/2403.17860v2", "datetime": "2024-04-02 12:25:57", "query": "synthetic data generation llms", "linkedin": "\ud83d\ude80 Exciting news in the world of Natural Language Processing! \ud83c\udf1f\n\nAre you interested in cutting-edge research on mitigating errors in NLP models during classification tasks? Check out this groundbreaking study that explores the use of large language models (LLMs) for data augmentation to address high confidence misclassifications. \n\nThe research compares the effectiveness of synthetic data generated by LLMs versus human-provided data in reducing wrong predictions while maintaining accuracy levels. Results show that LLMs can significantly reduce high confidence misclassifications, offering a more scalable solution compared to human-provided data.\n\nRead more about this innovative approach and its implications for NLP models here: http://arxiv.org/abs/2403.17860v2\n\n#NLP #LLMs #DataAugmentation #AI #TechResearch #Innovation #ArtificialIntelligence #MachineLearning #TechTrends", "x": "Exciting research on leveraging large language models for data augmentation in NLP to reduce high confidence misclassifications! \ud83d\ude80\ud83e\udd16 Check out the study comparing human-generated vs. LLM-generated synthetic data for classification tasks. Results show promising effectiveness and scalability. Read more at: http://arxiv.org/abs/2403.17860v2 #AI #NLP #LLM #DataAugmentation #Research", "source_id": "4fccfa3f8234a42278df83e186b4f7516f78cd704f1f8d04351df9001db67be5", "page_number": 1}, "score": null, "embedding": [-0.21187737584114075, -0.144776850938797, 0.02318030782043934, -0.1063542366027832, 0.16847851872444153, 0.08783604949712753, -0.09416191279888153, -0.12090016156435013, 0.23620939254760742, -0.3144957721233368, 0.08201296627521515, -0.07078663259744644, 0.13169200718402863, 0.1960277110338211, 0.1584893763065338, 0.16704308986663818, -0.15740519762039185, 0.20012041926383972, -0.1747296005487442, 0.14268344640731812, 0.28332599997520447, -0.0909186378121376, 0.04555460438132286, -0.07405633479356766, -0.07345584779977798, -0.06807492673397064, -0.19900722801685333, -0.28271007537841797, -0.22304318845272064, -1.4243792295455933, 0.1305612176656723, -0.18254190683364868, 0.42051416635513306, -0.17403599619865417, -0.06704200804233551, -0.030339589342474937, -0.24088190495967865, 0.17687919735908508, -0.07381585240364075, 0.15252038836479187, -0.07996097207069397, -0.06129855290055275, -0.10296111553907394, -0.15178504586219788, 0.2709576487541199, -0.2973276376724243, -0.20988832414150238, -0.15812285244464874, -0.6306280493736267, 0.011844421736896038, -0.24917304515838623, -0.14581464231014252, 0.07274281233549118, 0.3053082525730133, 0.23612554371356964, 0.00031514879083260894, 0.4045030176639557, 0.1955689638853073, 0.06767717003822327, 0.14696885645389557, 0.13193745911121368, 0.3805449604988098, -1.0780584812164307, 0.2147429883480072, -0.07001551985740662, 0.22775086760520935, -0.11516852676868439, -0.3073274791240692, 0.003356871660798788, 0.011441130191087723, -0.15418614447116852, 0.15777409076690674, 0.3562445044517517, 0.2555287480354309, 0.23722761869430542, 0.36356601119041443, 0.14603900909423828, -0.3036997616291046, 0.1950850635766983, 0.08621452748775482, 0.34401535987854004, -0.02130407840013504, -0.11329497396945953, -0.5054540038108826, -0.038526006042957306, -0.09420305490493774, 0.11323251575231552, -0.1032792255282402, 0.0572981983423233, -0.2188667207956314, -0.05270480737090111, -0.022952787578105927, -0.10717914998531342, 0.34496110677719116, 0.08840445429086685, 0.1878531277179718, 0.08921486884355545, 0.19796156883239746, -0.2933236062526703, 0.726256787776947, -0.20031188428401947, 0.043196894228458405, -0.26799139380455017, -0.12360315769910812, 0.2176218032836914, -0.14848031103610992, -0.3150935769081116, -0.21988064050674438, -0.11432711035013199, -0.15134724974632263, 0.02031281404197216, 0.07088794559240341, -0.1553734987974167, -0.011636096984148026, -0.07580693066120148, -0.0841653123497963, 0.6719228029251099, -0.07716140896081924, -0.21578148007392883, 0.13091573119163513, -0.14394043385982513, 0.08007846027612686, -0.004262122325599194, -0.18036775290966034, -0.02081672102212906, -0.1072036549448967, 0.20465639233589172, 0.6119037866592407, 0.053024519234895706, -0.013823749497532845, 0.12015057355165482, -0.13832901418209076, -0.36415883898735046, -0.11552301049232483, 0.22135649621486664, -0.1730324923992157, -0.037171974778175354, -0.030536023899912834, 0.10737390071153641, 0.11964188516139984, -0.09913487732410431, 0.04185626283288002, -0.025674259290099144, 0.02245919778943062, -0.5081172585487366, 0.925348162651062, -0.20284079015254974, 0.05057017505168915, -0.21981023252010345, -0.2558691203594208, -0.1215970441699028, 0.32423093914985657, -0.2763233780860901, -0.1444149911403656, 0.27198678255081177, 0.02579585276544094, 0.1984017938375473, -0.08054925501346588, -0.44736847281455994, -0.25182294845581055, 0.04015631228685379, -0.05609462782740593, -0.24938388168811798, 0.7143455743789673, -0.07448387891054153, -0.1499778777360916, -0.19562023878097534, -0.020999737083911896, 0.39274999499320984, -0.06783446669578552, 0.2975768446922302, -0.03634040802717209, -0.035298559814691544, 0.05417142063379288, -0.3566654622554779, 0.2282739132642746, -0.5995250940322876, -0.19448070228099823, -0.05802714452147484, 0.19836513698101044, -0.026842376217246056, -0.13764485716819763, -0.21666671335697174, 0.09236080944538116, 0.05347706750035286, -0.26509368419647217, -0.0028201478999108076, -0.22163207828998566, 0.29775556921958923, 0.09561651200056076, -0.24258127808570862, 0.2171596735715866, 0.03412620350718498, -0.09654124081134796, -0.17414140701293945, -0.15997901558876038, -0.06536814570426941, -0.005913130473345518, 0.1693975180387497, -0.09061725437641144, -0.09163734316825867, 0.33966702222824097, 0.2794054448604584, -0.11812885850667953, 0.11085357517004013, 0.09007801860570908, -0.051891494542360306, 0.09680327773094177, 0.16770444810390472, 0.4339732825756073, -0.4052797257900238, -0.05067423731088638, 0.3570442497730255, -0.0035742996260523796, -0.00989274587482214, 0.1238502636551857, 0.3244912028312683, 0.35594889521598816, 0.040645208209753036, 0.26648035645484924, 0.05247640237212181, 0.3059855103492737, -0.19545020163059235, -1.207869291305542, -0.15305057168006897, 0.30066660046577454, -0.009440707042813301, 0.26874783635139465, -0.27053120732307434, 0.08391578495502472, 0.008087648078799248, 0.27173808217048645, 0.5558276772499084, 0.09210389107465744, -0.030784593895077705, -0.03378487378358841, 0.2249690294265747, 0.1297358274459839, 0.013203282840549946, -0.12446446716785431, 0.08560933917760849, -0.3177913725376129, 0.38713619112968445, -0.2271975874900818, 0.015711022540926933, 0.05609256401658058, -0.9378836154937744, -0.10444065183401108, -0.05590551719069481, 0.6909571290016174, -0.36877962946891785, 0.17137302458286285, -0.16081400215625763, -0.007771321572363377, 0.26790472865104675, -0.04415342956781387, -0.41224274039268494, 0.6454294323921204, 0.016565581783652306, 0.20038975775241852, -0.05813243240118027, 0.06471564620733261, -0.11078440397977829, -0.21080979704856873, 0.008327520452439785, 0.16697971522808075, -0.7546325922012329, -0.25387340784072876, 0.05554937943816185, -0.13235269486904144, -0.06423930078744888, -0.41052863001823425, 0.22854602336883545, 0.2077798694372177, 0.11376574635505676, 0.3104441165924072, -0.04038134962320328, -0.14119401574134827, 0.07565145194530487, -0.7082957625389099, 0.1578107476234436, -0.15533509850502014, 0.044834721833467484, 0.387326180934906, -0.13542751967906952, 0.04799919202923775, -0.23801934719085693, 0.34348830580711365, -0.31827446818351746, -0.055126119405031204, -0.03177319094538689, 0.2792668044567108, 0.0034211655147373676, -0.19095337390899658, 0.8353658318519592, 0.04404481500387192, 0.06863164156675339, 0.1751292496919632, 0.16087546944618225, -0.3104541301727295, -0.36477401852607727, -0.3042603135108948, 0.08043579757213593, 0.584552526473999, 0.23783722519874573, 0.35756269097328186, 0.04420514032244682, 0.28618499636650085, -0.02501070126891136, 0.47074365615844727, 0.03402162715792656, 0.031692326068878174, 0.18675576150417328, 0.02902974747121334, 0.01590788923203945, -0.2993856370449066, 0.0054594241082668304, 0.0865020602941513, 0.09123663604259491, -1.1194052696228027, -0.19072610139846802, -0.16591638326644897, 0.3546641767024994, 0.03792308643460274, -0.0987798348069191, 0.21231591701507568, -0.021063653752207756, 0.1611359715461731, 0.19442275166511536, -0.2751191258430481, 0.08208410441875458, 0.17468366026878357, 0.06320665031671524, 0.24652791023254395, -0.13451749086380005, 0.23420806229114532, -0.08830586820840836, 0.15416398644447327, -0.33981677889823914, 0.18325620889663696, 0.1231195330619812, 1.0888649225234985, 0.015018091537058353, -0.0027966538909822702, 0.3302270770072937, -0.11179791390895844, -0.07430104166269302, 0.014780785888433456, -0.24154993891716003, -0.17405319213867188, 0.21952563524246216, 0.6936688423156738, -0.06864948570728302, -0.04189971834421158, 0.6111531853675842, -0.27697136998176575, -0.13598038256168365, 0.17086286842823029, 0.0554693266749382, 0.324670672416687, 0.02227381058037281, 0.26057592034339905, -0.16602519154548645, 0.5693451166152954, -0.12065854668617249, 0.06256729364395142, -0.35365399718284607, 0.06750036776065826, 0.13972437381744385, -0.31208449602127075, 0.12949174642562866, -0.08631333708763123, -0.01840822771191597, 0.05651261284947395, 0.08395704627037048, 0.08561667054891586, -0.4159099757671356, -0.057430144399404526, -0.2760006785392761, 0.0031131806317716837, -0.22067326307296753, -0.058455146849155426, 0.057387810200452805, -0.43528279662132263], "sparse_embedding": null}, {"id": "f51dc20b212072ef6ae5b0ac84e06bd2df8b73464d6eae3b2af50f71c42a9db0", "content": "The rapid development of Large Language Models (LLMs) has led to great\nstrides in model capabilities like long-context understanding and reasoning.\nHowever, as LLMs are able to process longer contexts, it becomes more\nchallenging to evaluate whether they have acquired certain capabilities, since\nthe length of text (e.g., 200K tokens) they can process far exceeds what humans\ncan reliably assess in a reasonable duration. In this paper, we propose using\ncomplex synthetic tasks as a proxy evaluation method, and present S3Eval, a\nSynthetic, Scalable, Systematic evaluation suite for LLMs evaluation. The\nsynthetic nature of S3Eval provides users full control over the dataset,\nallowing them to systematically probe LLM capabilities by scaling text length\nand varying task difficulty across diverse scenarios. The strong correlation\nbetween S3Eval and real-world benchmarks demonstrates the soundness of using\nS3Eval for evaluation of LLMs. S3Eval provides a flexible and infinite\nlong-context data generation method. We have generated a comprehensive dataset\ncalled S3Eval-Standard, and experimental results have shown that it poses\nsignificant challenges for all existing LLMs.", "dataframe": null, "blob": null, "meta": {"type": "arxiv", "url": "http://arxiv.org/abs/2310.15147v2", "title": "S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Models", "content": "http://arxiv.org/pdf/2310.15147v2", "datetime": "2024-04-06 15:20:18", "query": "synthetic data generation llms", "linkedin": "\ud83d\ude80 Exciting developments in the field of Large Language Models (LLMs)! A recent paper introduces S3Eval, a Synthetic, Scalable, Systematic evaluation suite designed to assess LLM capabilities in processing long contexts. By utilizing complex synthetic tasks, S3Eval offers a flexible and controlled method to evaluate LLM performance across diverse scenarios. \n\nThe correlation between S3Eval and real-world benchmarks showcases its effectiveness in gauging LLM capabilities. Experimental results with the S3Eval-Standard dataset have revealed significant challenges for existing LLMs, highlighting the potential of this evaluation method.\n\nRead more about S3Eval and its implications for LLM assessment here: http://arxiv.org/abs/2310.15147v2\n\n#AI #NLP #LLMs #Technology #Research #Innovation", "x": "\ud83d\ude80 Exciting development in Large Language Models (LLMs) evaluation! Check out S3Eval, a Synthetic, Scalable, Systematic evaluation suite that challenges existing LLMs with complex synthetic tasks. Learn more at: http://arxiv.org/abs/2310.15147v2 #AI #NLP #LLMs #TechInnovation \ud83e\udde0\ud83d\udd0d", "source_id": "aa4c1b5dcd1138e0ced3fc41237db46b75204561bcfd8accce11f030c799d98a", "page_number": 1}, "score": null, "embedding": [-0.35848429799079895, 0.0015975757269188762, 0.10478750616312027, -0.04485936462879181, 0.03236818686127663, -0.04530768096446991, -0.36183643341064453, 0.02879466861486435, 0.18743020296096802, -0.3061543405056, -0.00938084814697504, -0.041489582508802414, 0.19368398189544678, 0.03167246654629707, 0.27485358715057373, 0.19041377305984497, -0.17045974731445312, 0.12452284246683121, -0.33135512471199036, -0.08223668485879898, 0.37406525015830994, -0.3209313452243805, 0.008382098749279976, 0.0352679006755352, 0.2671791613101959, 0.13905414938926697, -0.08844809234142303, -0.14477965235710144, -0.26733896136283875, -1.558762550354004, 0.23951765894889832, -0.14924439787864685, 0.3658835291862488, -0.03743365406990051, -0.1499825268983841, 0.12701919674873352, -0.2836548984050751, 0.15643103420734406, 0.04554998502135277, 0.20786502957344055, 0.09319771826267242, 0.3803851902484894, -0.08678082376718521, -0.10990755259990692, -0.29475969076156616, -0.4050459563732147, -0.3071819245815277, 0.1453532874584198, -0.5592555999755859, -0.0339779257774353, -0.19142179191112518, -0.2950328290462494, 0.2275005280971527, 0.16734729707241058, 0.014172518625855446, 0.1267213523387909, 0.15832951664924622, 0.15919561684131622, 0.1348644495010376, -0.1425934135913849, 0.28758156299591064, 0.28799834847450256, -1.014596939086914, 0.2760965824127197, -0.006536900531500578, 0.2432277798652649, 0.07114250212907791, 0.009081157855689526, 0.2705484926700592, 0.12523795664310455, -0.2046426385641098, 0.06773227453231812, 0.36536914110183716, 0.46742182970046997, 0.37637007236480713, 0.28620782494544983, 0.14732956886291504, -0.0958731397986412, 0.19212573766708374, 0.06041484326124191, 0.30982035398483276, -0.22156114876270294, -0.06994183361530304, -0.1404319852590561, -0.2884107828140259, -0.06747601181268692, -0.28887057304382324, 0.0029375539161264896, 0.04246702417731285, -0.02517695166170597, -0.10103089362382889, -0.23508398234844208, -0.13545939326286316, 0.2760877311229706, -0.2546563446521759, -0.01776576228439808, 0.024495406076312065, 0.0813588947057724, -0.2407192885875702, 0.6029932498931885, -0.09987611323595047, 0.21509747207164764, -0.07395809888839722, -0.14799749851226807, 0.34901049733161926, 0.015023541636765003, -0.19878095388412476, -0.1624128818511963, -0.10655558109283447, -0.11246078461408615, -0.0002865247952286154, 0.05580634996294975, -0.23010651767253876, -0.043920837342739105, 0.05029435083270073, -0.0424649678170681, 0.5266819596290588, -0.18885129690170288, -0.09248797595500946, -0.09128803014755249, -0.3690141439437866, 0.43355700373649597, 0.009309403598308563, -0.2469925582408905, 0.1655445545911789, -0.19444972276687622, 0.2932610511779785, 0.40570268034935, 0.13912366330623627, -0.0844905748963356, 0.15913920104503632, 0.06686001271009445, -0.4477471709251404, -0.138241708278656, -0.061343900859355927, -0.28314465284347534, -0.1618902087211609, -0.0983930453658104, 0.04405909776687622, 0.10711152106523514, -0.03409166261553764, 0.14152835309505463, 0.3366810083389282, -0.11621317267417908, -0.33420130610466003, 0.7228467464447021, 0.10956450551748276, 0.13364605605602264, -0.378818541765213, -0.16564056277275085, 0.20226337015628815, 0.23282606899738312, 0.06858892738819122, -0.3032062351703644, 0.2753695249557495, 0.13642780482769012, 0.17485882341861725, 0.18263626098632812, -0.46176788210868835, -0.051488351076841354, -0.020929502323269844, 0.25366970896720886, -0.1463349312543869, 0.7454001307487488, -0.1089019924402237, -0.4548723101615906, -0.06362710148096085, -0.013454850763082504, 0.08831803500652313, -0.0012239809148013592, 0.11935895681381226, 0.04527544602751732, -0.15761306881904602, 0.055649686604738235, -0.09183737635612488, 0.19080807268619537, -0.6268976926803589, -0.09857518970966339, 0.10528022050857544, 0.16188734769821167, -0.0063082510605454445, -0.20455855131149292, -0.09060220420360565, 0.2780018746852875, -0.057027511298656464, -0.26887640357017517, 0.02715299278497696, -0.12916573882102966, 0.0702575221657753, 0.07513020932674408, -0.12862548232078552, 0.38217779994010925, -0.017893170937895775, 0.010457301512360573, -0.01927649788558483, -0.3323343098163605, 0.11169102787971497, 0.04066379368305206, 0.1316136121749878, -0.1365717649459839, 0.24171008169651031, 0.20375174283981323, 0.0022997877094894648, -0.21001090109348297, 0.2476046085357666, -0.09222674369812012, -0.09866239875555038, 0.17675365507602692, 0.3513653576374054, 0.31428059935569763, -0.4720105528831482, -0.03685186803340912, 0.2938949465751648, -0.044259510934352875, -0.11742214858531952, -0.00656198849901557, 0.15421336889266968, 0.025236835703253746, -0.2426232397556305, 0.30958855152130127, 0.0587269589304924, 0.09140915423631668, -0.18000087141990662, -1.224050521850586, 0.0007699818233959377, 0.2621045708656311, -0.0013086776016280055, 0.22985722124576569, -0.28706490993499756, -0.06621386855840683, -0.08507630974054337, 0.22324460744857788, 0.03467332571744919, 0.2962604761123657, 0.08908036351203918, -0.26463988423347473, 0.030241573229432106, 0.10373026132583618, -0.0662844181060791, -0.32555273175239563, 0.04269104823470116, -0.3792259097099304, 0.2765428423881531, -0.2718571722507477, 0.13738900423049927, 0.06944972276687622, -0.5222581624984741, -0.10317353904247284, -0.3599128723144531, 0.9009602069854736, -0.32030075788497925, -0.09779156744480133, -0.26172780990600586, 0.11061755567789078, 0.09862162172794342, -0.016203241422772408, -0.4937795400619507, 0.4063761830329895, 0.12181771546602249, 0.19868694245815277, 0.1280672401189804, 0.11286643892526627, 0.06632617115974426, -0.23247578740119934, -0.10426025837659836, 0.1545167863368988, -0.6912596225738525, -0.2467132955789566, 0.12530116736888885, 0.2039048969745636, -0.14665354788303375, -0.15006765723228455, 0.059599436819553375, 0.22873151302337646, 0.028801845386624336, 0.1750662624835968, -0.09971769154071808, -0.13058269023895264, 0.020104965195059776, -0.6513299345970154, 0.21007002890110016, -0.14688940346240997, -0.1497368961572647, 0.1803847998380661, 0.0824158787727356, -0.1672765612602234, 0.025355743244290352, 0.252594918012619, -0.08089540153741837, -0.06233997642993927, -0.018530765548348427, -0.17110440135002136, -0.23285235464572906, -0.16725026071071625, 0.5003700852394104, -0.2569662928581238, 0.1675364077091217, 0.1208374947309494, 0.075835682451725, -0.0687863677740097, -0.23982562124729156, -0.14425255358219147, -0.11100603640079498, 0.5790972113609314, 0.11290065944194794, 0.02984621189534664, 0.1751919537782669, 0.08007261157035828, 0.04268860071897507, 0.25864213705062866, 0.21669240295886993, 0.06624661386013031, -0.047141700983047485, -0.0993492603302002, 0.04804876074194908, -0.25278884172439575, -0.15802861750125885, 0.18130339682102203, -0.10488761216402054, -1.0592572689056396, 0.031171267852187157, -0.08782222121953964, 0.22000738978385925, -0.07754570990800858, -0.07963177561759949, 0.21247051656246185, -0.13714154064655304, -0.061533503234386444, 0.04851701110601425, -0.061563823372125626, 0.2639119029045105, 0.1225975751876831, 0.12960949540138245, 0.23012375831604004, -0.12377127259969711, 0.42167457938194275, -0.14319711923599243, 0.30985888838768005, -0.5097527503967285, 0.10569097101688385, 0.2143355756998062, 1.0496634244918823, -0.10421421378850937, -0.0009752041078172624, 0.4330388903617859, 0.029114242643117905, -0.1154932752251625, -0.04759583994746208, -0.1742101013660431, -0.005389671307057142, -0.010057150386273861, 0.6417298913002014, -0.02090759016573429, 0.12018411606550217, 0.2704838216304779, -0.19913803040981293, 0.06805586814880371, 0.2656058371067047, 0.23985689878463745, 0.6060487031936646, 0.027039259672164917, 0.12355917692184448, -0.15121880173683167, 0.6927741765975952, -0.012215000577270985, -0.01072030607610941, -0.3562093675136566, -0.10581261664628983, 0.003069165861234069, -0.3170423209667206, 0.06651562452316284, -0.19205491244792938, 0.17192643880844116, 0.3926302194595337, 0.18584807217121124, 0.13374418020248413, -0.03559572249650955, -0.134162038564682, -0.17669358849525452, -0.09032878279685974, -0.39979878067970276, 0.08671089261770248, 0.2629711627960205, -0.07005271315574646], "sparse_embedding": null}, {"id": "3b778acbda18010571b2a242bc6999da6901d53ccd85463d54236ea987ab3a9d", "content": "Recognizing if LLM output can be grounded in evidence is central to many\ntasks in NLP: retrieval-augmented generation, summarization, document-grounded\ndialogue, and more. Current approaches to this kind of \"fact-checking\" are\nbased on verifying each piece of a model generation against potential evidence\nusing an LLM. However, this process can be very computationally expensive,\nrequiring many calls to LLMs to check a single response. In this work, we show\nhow to build small models that have GPT-4-level performance but for 400x lower\ncost. We do this by constructing synthetic training data with GPT-4, which\ninvolves creating realistic yet challenging instances of factual errors via a\nstructured generation procedure. Training on this data teaches models to check\neach fact in the claim and recognize synthesis of information across sentences.\nFor evaluation, we unify pre-existing datasets into a benchmark LLM-AggreFact,\ncollected from recent work on fact-checking and grounding LLM generations. Our\nbest system MiniCheck-FT5 (770M parameters) outperforms all systems of\ncomparable size and reaches GPT-4 accuracy. We release LLM-AggreFact, code for\ndata synthesis, and models.", "dataframe": null, "blob": null, "meta": {"type": "arxiv", "url": "http://arxiv.org/abs/2404.10774v1", "title": "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents", "content": "http://arxiv.org/pdf/2404.10774v1", "datetime": "2024-04-16 17:59:10", "query": "synthetic data generation llms", "linkedin": "\ud83d\ude80 Exciting news in the world of NLP and LLMs! Researchers have developed a groundbreaking approach to fact-checking LLM outputs, significantly reducing computational costs while maintaining GPT-4-level performance. By training small models on synthetic data generated with GPT-4, they have successfully improved the efficiency of verifying facts in model generations. The newly introduced benchmark LLM-AggreFact, along with the MiniCheck-FT5 system, outperforms comparable models and achieves GPT-4 accuracy. Learn more about this innovative work at: http://arxiv.org/abs/2404.10774v1 #NLP #LLM #AI #FactChecking #Innovation \ud83d\udd0d\ud83d\udcca\ud83d\udd2c", "x": "\ud83d\ude80 Exciting new research on fact-checking in NLP! Learn how small models with GPT-4-level performance are built at 400x lower cost. Check out MiniCheck-FT5, outperforming others of comparable size. Find out more at: http://arxiv.org/abs/2404.10774v1 #AI #NLP #LLM #research #factchecking", "source_id": "b9cc3e96294ad553fbc4c6f6e413034b38772a5e09e7d5475479c3338b5d34f3", "page_number": 1}, "score": null, "embedding": [-0.24489767849445343, 0.024771815165877342, 0.11332601308822632, -0.08777137845754623, 0.299771785736084, 0.2517421841621399, -0.24166202545166016, -0.07232672721147537, 0.15615323185920715, -0.3335495591163635, 0.18184220790863037, -0.1765809804201126, 0.15131573379039764, 0.3290174603462219, -0.05932466685771942, 0.08044549822807312, -0.15943312644958496, 0.2986326813697815, -0.007857013493776321, 0.04201221466064453, 0.3500896394252777, -0.2946479320526123, -0.04459037631750107, -0.08301432430744171, 0.10804054141044617, 0.17545993626117706, -0.04238557815551758, -0.07000923901796341, -0.24876338243484497, -1.4215278625488281, -0.05915524438023567, -0.0507311150431633, 0.3764212727546692, 0.021718956530094147, 0.05341435223817825, 0.04948800429701805, -0.2780010998249054, 0.1587284803390503, -0.1735297292470932, 0.14896520972251892, 0.04588188976049423, 0.09605715423822403, 0.012238327413797379, -0.18247655034065247, -0.11035076528787613, -0.30142098665237427, -0.16304460167884827, 0.10826417803764343, -0.4953683614730835, -0.3309241533279419, -0.06409389525651932, -0.06090308353304863, -0.024076033383607864, 0.043340351432561874, -0.0239630825817585, 0.0004878451582044363, 0.27596110105514526, 0.12598669528961182, 0.2876015305519104, 0.017919354140758514, 0.27214646339416504, 0.5538138151168823, -1.1221377849578857, 0.08997482061386108, 0.031624890863895416, 0.1730901300907135, -0.04877348244190216, 0.02171856164932251, 0.16131755709648132, 0.15810653567314148, -0.17462432384490967, -0.06692488491535187, 0.12279929220676422, 0.2993437945842743, 0.1364125907421112, 0.24711859226226807, 0.12297190725803375, -0.18626195192337036, 0.023338397964835167, -0.06619830429553986, -0.10881505906581879, 0.08515167236328125, -0.13044750690460205, -0.009846288710832596, -0.2330990433692932, -0.1648934781551361, 0.017297882586717606, 0.020565830171108246, 0.24672353267669678, -0.04051751643419266, 0.017295056954026222, -0.03560780733823776, -0.14379297196865082, 0.26959484815597534, -0.11023427546024323, 0.16836407780647278, 0.18752743303775787, 0.06595935672521591, -0.043660953640937805, 0.5830998420715332, -0.0893031433224678, 0.12416823208332062, -0.22029384970664978, 0.12973982095718384, 0.08140739798545837, -0.032685261219739914, -0.20986363291740417, 0.06143441051244736, -0.14391300082206726, -0.1757129579782486, -0.0680936649441719, 0.2546316385269165, 0.10128585249185562, -0.1706414669752121, 0.04050520434975624, -0.12063415348529816, 0.3678762912750244, -0.08710464090108871, -0.20603802800178528, 0.025794576853513718, -0.24110108613967896, 0.12865565717220306, -0.2546003460884094, -0.12756046652793884, 0.2173849642276764, -0.22223961353302002, 0.13691702485084534, 0.39779287576675415, 0.12627151608467102, 0.17904803156852722, 0.12289884686470032, -0.11679986119270325, -0.4250882863998413, -0.2534197270870209, 0.23370927572250366, -0.16259920597076416, 0.39305999875068665, 0.05236067995429039, -0.003010575659573078, 0.4142020344734192, -0.08390432596206665, 0.08945050835609436, 0.04418230056762695, 0.03836431726813316, -0.5370074510574341, 0.7218722105026245, -0.2342934012413025, 0.03777607902884483, -0.16034385561943054, -0.4251599907875061, 0.1379646360874176, 0.33037203550338745, -0.21479882299900055, -0.23326388001441956, 0.3431151509284973, 0.014459947124123573, 0.13701659440994263, 0.016161467880010605, -0.47479069232940674, 0.04240143299102783, -0.07071799784898758, 0.014700457453727722, -0.2020588517189026, 0.6643903255462646, -0.08950944244861603, -0.3327251672744751, -0.3037571907043457, 0.11591409146785736, 0.3602806329727173, -0.40405961871147156, 0.2079903781414032, 0.20333224534988403, 0.015363877639174461, -0.32832589745521545, -0.22167229652404785, -0.28133270144462585, -0.5339145660400391, 0.09048773348331451, -0.11612208187580109, 0.27428746223449707, 0.15429341793060303, -0.29755669832229614, -0.17244884371757507, 0.2448420226573944, 0.014714025892317295, -0.08835753798484802, 0.02226327359676361, -0.32014715671539307, 0.2009958177804947, -0.03185264766216278, -0.3070489764213562, 0.0899343267083168, -0.03731667995452881, 0.17445632815361023, -0.17367838323116302, -0.2165086269378662, -0.12126510590314865, 0.12933677434921265, 0.18161866068840027, -0.16873714327812195, -0.012683156877756119, -0.15029706060886383, -0.03378137946128845, 0.026060916483402252, 0.0255748238414526, 0.01946772076189518, -0.1319957673549652, 0.0012222614604979753, 0.3552854061126709, 0.33242297172546387, -0.18218031525611877, -0.10219789296388626, 0.10524836927652359, -0.227272629737854, -0.19501036405563354, 0.03777482360601425, 0.21338653564453125, 0.38220471143722534, -0.37903764843940735, 0.1987294852733612, -0.013637064956128597, 0.06798097491264343, -0.11121775209903717, -1.0931999683380127, -0.29621756076812744, 0.2416556030511856, 0.31571054458618164, 0.4429347515106201, -0.3547252416610718, 0.1457219123840332, 0.1572628915309906, 0.009648572653532028, 0.2871696352958679, 0.06472210586071014, 0.20443099737167358, -0.16301411390304565, 0.16948699951171875, -0.13777372241020203, -0.042458295822143555, -0.15421634912490845, 0.03637031465768814, -0.19491547346115112, 0.17703351378440857, -0.26977595686912537, 0.04713036119937897, -0.07160937041044235, -0.6790460348129272, 0.05070190131664276, -0.228683203458786, 0.7717533111572266, -0.14339196681976318, 0.13298581540584564, -0.00216200714930892, 0.028044937178492546, 0.1332312673330307, -0.02834535948932171, -0.3456297218799591, 0.46392494440078735, 0.12698590755462646, -0.031646158546209335, 0.06882455199956894, 0.12078545987606049, -0.1517791450023651, -0.26919466257095337, -0.002273108810186386, 0.12513086199760437, -0.6115936040878296, -0.34110167622566223, 0.011349090375006199, -0.13350418210029602, 0.054359689354896545, -0.20811180770397186, 0.22758954763412476, 0.19610600173473358, -0.07233989238739014, 0.43616706132888794, -0.033773377537727356, -0.2001662254333496, -0.15650933980941772, -0.5496731996536255, 0.0358540304005146, -0.2616675794124603, -0.05091353505849838, 0.21378283202648163, -0.07442694902420044, -0.06679287552833557, -0.13865940272808075, 0.4080488979816437, -0.14169704914093018, -0.1427837461233139, -0.055166929960250854, 0.3003440499305725, -0.20694716274738312, 0.2816014289855957, 0.5293822288513184, 0.07673567533493042, 0.2671310007572174, 0.13177059590816498, 0.15076719224452972, -0.13289514183998108, -0.36360904574394226, -0.32486164569854736, -0.21365748345851898, 0.38791465759277344, 0.21772171556949615, 0.1332206279039383, 0.07762634754180908, -0.05076819285750389, 0.2716550827026367, 0.4362708330154419, 0.14381133019924164, 0.2032375931739807, -0.05095309764146805, 0.048725225031375885, 0.16479922831058502, -0.19194296002388, -0.08129335939884186, 0.04370344802737236, 0.08618157356977463, -1.101419448852539, -0.04725700616836548, -0.16149529814720154, 0.4304172396659851, -0.30680814385414124, -0.11177344620227814, 0.11419408023357391, -0.051363732665777206, 0.03146618604660034, 0.178850919008255, -0.05726664513349533, 0.06810370832681656, 0.30377626419067383, -0.2853488326072693, 0.1249655932188034, 0.18471422791481018, 0.24745529890060425, -0.3797200322151184, -0.15747228264808655, -0.3124513626098633, 0.16753464937210083, 0.3032509386539459, 0.900011420249939, 0.0019178339280188084, 0.057243216782808304, 0.2980411648750305, -0.06485901772975922, 0.12073211371898651, 0.16721299290657043, -0.06735079735517502, -0.15898939967155457, -0.06173669546842575, 0.8125963807106018, 0.08518106490373611, 0.13361400365829468, 0.5482099056243896, -0.21665409207344055, 0.06824369728565216, 0.1817592978477478, -0.018296638503670692, 0.3229610025882721, -0.15540948510169983, 0.09110085666179657, -0.02094460465013981, 0.4381689727306366, -0.1592206358909607, 0.26027947664260864, -0.30951517820358276, -0.16486817598342896, 0.0057158088311553, -0.04218393564224243, 0.035610973834991455, 0.06748049706220627, -0.16500402987003326, 0.3984247148036957, 0.3229164779186249, 0.039306432008743286, -0.05396384745836258, 0.10627150535583496, -0.27749499678611755, -0.05454543977975845, -0.041989073157310486, 0.23855853080749512, 0.11828915774822235, -0.2584190368652344], "sparse_embedding": null}, {"id": "4b9cf588260072c8784faf77ea3cf248de31ac491102dcd37aec1eae19fdd159", "content": "Large language models (LLMs) are remarkable data annotators. They can be used\nto generate high-fidelity supervised training data, as well as survey and\nexperimental data. With the widespread adoption of LLMs, human gold--standard\nannotations are key to understanding the capabilities of LLMs and the validity\nof their results. However, crowdsourcing, an important, inexpensive way to\nobtain human annotations, may itself be impacted by LLMs, as crowd workers have\nfinancial incentives to use LLMs to increase their productivity and income. To\ninvestigate this concern, we conducted a case study on the prevalence of LLM\nusage by crowd workers. We reran an abstract summarization task from the\nliterature on Amazon Mechanical Turk and, through a combination of keystroke\ndetection and synthetic text classification, estimate that 33-46% of crowd\nworkers used LLMs when completing the task. Although generalization to other,\nless LLM-friendly tasks is unclear, our results call for platforms,\nresearchers, and crowd workers to find new ways to ensure that human data\nremain human, perhaps using the methodology proposed here as a stepping stone.\nCode/data: https://github.com/epfl-dlab/GPTurk", "dataframe": null, "blob": null, "meta": {"type": "arxiv", "url": "http://arxiv.org/abs/2306.07899v1", "title": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks", "content": "http://arxiv.org/pdf/2306.07899v1", "datetime": "2023-06-13 16:46:24", "query": "synthetic data generation llms", "linkedin": "\ud83d\ude80 Exciting insights into the impact of Large Language Models (LLMs) on crowdsourcing! \ud83e\udd16\ud83d\udcac\n\nA recent study delved into the prevalence of LLM usage by crowd workers in data annotation tasks. The findings showed that 33-46% of crowd workers leveraged LLMs to enhance their productivity and earnings. This raises important considerations for ensuring the integrity of human-generated data in the era of advanced AI technologies.\n\nFor a detailed overview of the study and its implications, check out the full paper here: http://arxiv.org/abs/2306.07899v1\n\n#LLMs #Crowdsourcing #AI #DataAnnotation #TechResearch #ArtificialIntelligence #NLP\n\nCode and data from the study are available at: https://github.com/epfl-dlab/GPTurk\n\nLet's keep exploring the intersection of human intelligence and AI advancements! \ud83c\udf10\ud83d\udca1\n\n#TechInnovation #Research #DataScience #MachineLearning #SocialMediaExpert #LinkedInPost", "x": "\ud83d\ude80 New research alert! Learn how Large Language Models impact crowd workers and human annotations in AI tasks. A case study found that 33-46% of workers used LLMs on Amazon Mechanical Turk. Check out the study here: http://arxiv.org/abs/2306.07899v1 #AI #LLMs #NLP #Research\n\nCode/data available at: https://github.com/epfl-dlab/GPTurk", "source_id": "4f042a7419d34c4e6c4062b8c5a5a576aa51c7925b8518cda9064fcfed77ea8b", "page_number": 1}, "score": null, "embedding": [-0.3446113169193268, -0.23002922534942627, 0.012291175313293934, -0.01784185878932476, 0.061887066811323166, -0.14213670790195465, -0.03900010883808136, -0.09666896611452103, 0.204078808426857, -0.35064199566841125, 0.11318489909172058, -0.02541397325694561, 0.0545683316886425, 0.31988197565078735, 0.16668209433555603, 0.15436159074306488, -0.11548511683940887, -0.027915509417653084, -0.37181356549263, -0.146237313747406, 0.27379998564720154, -0.1946173757314682, 0.0374549962580204, -0.04342114180326462, -0.16745761036872864, -0.06730791181325912, -0.3916100561618805, -0.15132220089435577, -0.3853778839111328, -1.3043313026428223, 0.27065369486808777, -0.12418132275342941, 0.5888561010360718, 0.11538673937320709, -0.13940002024173737, -0.013710364699363708, 0.045651379972696304, 0.2279273420572281, -0.018917083740234375, 0.3402582108974457, -0.1864681839942932, -0.017929010093212128, 0.11295180767774582, -0.0599459633231163, 0.00028282098355703056, -0.4557562470436096, -0.22024847567081451, -0.13784955441951752, -0.6061627864837646, 0.20582087337970734, -0.05660214275121689, -0.34433886408805847, -0.01999448984861374, 0.3556288182735443, 0.21798790991306305, -0.13541825115680695, 0.20605537295341492, 0.12039349228143692, 0.123565174639225, 0.07941567152738571, 0.315268874168396, 0.2741556763648987, -0.9707534313201904, 0.23759199678897858, -0.2039649337530136, 0.31148678064346313, -0.013288678601384163, 0.05708992853760719, 0.08236779272556305, -0.08451370894908905, 0.003992629237473011, 0.08718644082546234, 0.16205599904060364, 0.21125516295433044, 0.3102879524230957, 0.19895881414413452, 0.08869162201881409, -0.13901132345199585, 0.24206268787384033, -0.12711074948310852, -0.11480497568845749, 0.11646515130996704, 0.05158771947026253, -0.20510786771774292, -0.12209118157625198, 0.044071611016988754, -0.01291557028889656, -0.1612834632396698, 0.22012588381767273, -0.28385576605796814, -0.03398514539003372, -0.0861731767654419, -0.16862259805202484, 0.3380797207355499, -0.037908509373664856, -0.08080446720123291, 0.18850991129875183, 0.1919415444135666, -0.22425305843353271, 0.7163200378417969, -0.1149432510137558, 0.10783172398805618, -0.17472682893276215, -0.1329052597284317, 0.308031290769577, -0.0915079191327095, -0.21907028555870056, -0.17933039367198944, -0.09606579691171646, 0.036141157150268555, 0.03383379429578781, 0.30642542243003845, -0.13253401219844818, -0.06104642525315285, 0.08475696295499802, -0.04546848312020302, 0.4191812574863434, 0.11115454882383347, 0.026502294465899467, 0.2688315808773041, -0.3014450967311859, 0.013860564678907394, 0.020568417385220528, -0.05433191731572151, 0.07844673097133636, 0.02098606340587139, 0.13993684947490692, 0.5672350525856018, 0.4722268879413605, 0.08146361261606216, 0.1919202357530594, 0.03643380478024483, -0.7635665535926819, -0.1835721731185913, 0.0977984219789505, -0.03435052931308746, 0.10357706993818283, -0.15332208573818207, 0.11179787665605545, 0.2688734829425812, 0.05400729924440384, 0.07168533653020859, 0.024660231545567513, -0.0865032896399498, -0.2551039159297943, 0.8387208580970764, 0.04140797257423401, 0.020255066454410553, -0.17023198306560516, -0.18892879784107208, 0.17772434651851654, 0.24832379817962646, -0.08806158602237701, -0.17273738980293274, 0.2926671802997589, 0.1819872111082077, 0.5225852727890015, 0.3579050302505493, -0.44086697697639465, -0.10605181753635406, 0.030162660405039787, -0.053751736879348755, -0.07230647653341293, 0.6261501908302307, -0.13790802657604218, -0.5416116118431091, -0.15161949396133423, -0.024927765130996704, 0.21627604961395264, -0.09526491910219193, 0.1964091807603836, 0.00013336833217181265, -0.2156393975019455, 0.21392865478992462, -0.08830055594444275, 0.15449506044387817, -0.6373661160469055, 0.031450651586055756, -0.09324116259813309, 0.3534698188304901, 0.2086373269557953, -0.20442792773246765, -0.32716450095176697, 0.2307945340871811, -0.18746072053909302, -0.33870649337768555, -0.061574261635541916, -0.18094831705093384, 0.1485944539308548, 0.23110593855381012, 0.11420425772666931, 0.37108272314071655, -0.1445281058549881, -0.15269583463668823, -0.008897148072719574, -0.2471712976694107, -0.2421712726354599, -0.036871060729026794, 0.12302844971418381, -0.2222633957862854, -0.21543444693088531, 0.37343740463256836, 0.09557485580444336, -0.057721517980098724, 0.20669040083885193, 0.05785973370075226, -0.16121800243854523, -0.12434031814336777, 0.40018540620803833, 0.21995654702186584, -0.22510984539985657, -0.04440970718860626, 0.16626648604869843, 0.08152946829795837, -0.22386084496974945, 0.10832910239696503, 0.3946278989315033, 0.29169556498527527, -0.04633978754281998, 0.06783760339021683, 0.1826183795928955, 0.3645966947078705, -0.3138371706008911, -1.2466096878051758, -0.26902568340301514, 0.2769414782524109, 0.06367775797843933, 0.09581676870584488, -0.1892765909433365, 0.03386731445789337, 0.10688621550798416, 0.11048483103513718, 0.2757313549518585, 0.22650489211082458, -0.11429097503423691, -0.27830180525779724, 0.17769014835357666, 0.11043863743543625, 0.18866638839244843, -0.47292187809944153, 0.14301909506320953, -0.13999922573566437, 0.28443530201911926, 0.004606835078448057, -0.08025228977203369, -0.060262635350227356, -0.7217048406600952, 0.17185458540916443, -0.10595270246267319, 0.824509859085083, -0.03957429900765419, -0.26710689067840576, -0.24749481678009033, -0.14620287716388702, 0.38115906715393066, -0.21698446571826935, -0.5825871825218201, 0.4817289710044861, -0.05110285431146622, 0.06775125861167908, -0.20331363379955292, -0.015293385833501816, 0.024064958095550537, -0.32959845662117004, -0.039835549890995026, 0.03348394110798836, -0.5377172231674194, -0.29482850432395935, 0.12174350023269653, -0.06783381849527359, -0.2106010615825653, -0.21927011013031006, 0.11607799679040909, 0.11197817325592041, 0.13411954045295715, 0.4458104968070984, 0.03581525757908821, -0.2481595128774643, -0.1820584088563919, -0.43875783681869507, 0.224492609500885, -0.3073238134384155, 0.11632010340690613, 0.25180986523628235, -0.17363770306110382, -0.08099134266376495, -0.14047937095165253, 0.2826072871685028, -0.337566077709198, -0.26975899934768677, 0.15374855697155, 0.12164565920829773, -0.2099367380142212, -0.20941589772701263, 0.7656469345092773, 0.1086663082242012, 0.17246019840240479, 0.20673975348472595, 0.1393754929304123, -0.037760864943265915, -0.3548777103424072, -0.3242456018924713, 0.005870177410542965, 0.43839791417121887, 0.23729443550109863, -0.06799564510583878, 0.15405678749084473, 0.07291820645332336, 0.2339274287223816, 0.22316308319568634, 0.016170352697372437, 0.31690514087677, -0.06498516350984573, -0.05473890155553818, -0.0306851789355278, -0.4871050715446472, -0.013238859362900257, 0.009911393746733665, 0.04785574600100517, -1.0801700353622437, 0.12449586391448975, -0.10298073291778564, 0.3489472270011902, 0.018372396007180214, 0.04267866536974907, 0.11181516945362091, -0.09761021286249161, 0.1458185613155365, 0.22724418342113495, 0.015566214919090271, 0.1942850798368454, 0.17394177615642548, -0.2557942867279053, 0.1849406510591507, -0.0171201154589653, 0.4604552686214447, -0.04159868136048317, 0.040563032031059265, -0.32808029651641846, -0.07523130625486374, 0.14361122250556946, 1.07389497756958, -0.055578358471393585, -0.093827024102211, 0.26424551010131836, -0.1438254863023758, -0.03456764668226242, 0.33080288767814636, -0.041027627885341644, -0.15815074741840363, -0.09926497936248779, 0.7188711166381836, -0.08635369688272476, -0.09303339570760727, 0.20675408840179443, -0.26541489362716675, -0.19106633961200714, 0.1422611027956009, 0.15751662850379944, 0.24388337135314941, 0.05367119610309601, -0.06600884348154068, -0.30467137694358826, 0.5640103220939636, 0.11038137227296829, 0.12550662457942963, -0.6761223673820496, -0.008328828029334545, 0.06931068748235703, -0.19806279242038727, -0.32931771874427795, -0.23597756028175354, 0.18238139152526855, 0.1516280323266983, 0.18672633171081543, 0.018266892060637474, 0.06081622466444969, -0.09945856779813766, -0.1482730656862259, -0.039544858038425446, -0.1800912767648697, -0.09300395101308823, 0.07241924852132797, -0.13295519351959229], "sparse_embedding": null}]}